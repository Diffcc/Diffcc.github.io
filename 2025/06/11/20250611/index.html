

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="apple-touch-icon" sizes="76x76" href="../../../../img/ling.jpg">
  <link rel="icon" href="../../../../img/ling.jpg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Diffcc">
  <meta name="keywords" content="">
  
    <meta name="description" content="可编程处理单元**（Graphic Processor Unit）日益发展成为高并行、多线程、多核处理的计算利器，2006年11月，NVIDIA推出了CUDA**——一种通用并行计算平台和编程模型，通过NVIDIA GPU中的并行计算引擎，以比CPU更高效的方式解决复杂的计算问题。 本文基于CUDA官方文档：1. Preface — CUDA C++ Best Practices Guide 12">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA基础">
<meta property="og:url" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/index.html">
<meta property="og:site_name">
<meta property="og:description" content="可编程处理单元**（Graphic Processor Unit）日益发展成为高并行、多线程、多核处理的计算利器，2006年11月，NVIDIA推出了CUDA**——一种通用并行计算平台和编程模型，通过NVIDIA GPU中的并行计算引擎，以比CPU更高效的方式解决复杂的计算问题。 本文基于CUDA官方文档：1. Preface — CUDA C++ Best Practices Guide 12">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/CPU%E5%92%8CGPU%E7%9A%84%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/%E5%85%B3%E9%94%AE%E6%8A%BD%E8%B1%A1%E7%9A%84%E5%85%B3%E7%B3%BB.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/Grid_Block_Thread.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/3D%E7%BB%93%E6%9E%84.jpg">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/Matrix_Multiplication.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/subMatrix.jpg">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/Shared_memory.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/Graph.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/%E5%86%85%E5%AD%98%E5%AF%BC%E5%85%A5%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/%E8%B7%A8API%E5%90%8C%E6%AD%A5%E6%A8%A1%E5%BC%8F.png">
<meta property="article:published_time" content="2025-06-11T09:51:12.000Z">
<meta property="article:modified_time" content="2025-06-17T12:27:03.460Z">
<meta property="article:author" content="Diffcc">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/CPU%E5%92%8CGPU%E7%9A%84%E5%AF%B9%E6%AF%94.png">
  
  
  
  <title>CUDA基础 - </title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="../../../../css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="../../../../css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="../../../../css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"github.com","root":"/Diffcc/Diffcc.github.io/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"KJGUBUZKqbURalPPi4RThE5j-gzGzoHsz","app_key":"LLhQIl1R0Kiu8YUUshoGpnuy","server_url":"https://kjgubuzk.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/Diffcc/Diffcc.github.io/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="../../../../js/utils.js" ></script>
  <script  src="../../../../js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="../../../../index.html">
      <strong>C.</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../index.html" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('../../../../img/default.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CUDA基础"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-06-11 17:51" pubdate>
          2025年6月11日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          15k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          127 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CUDA基础</h1>
            
            
              <div class="markdown-body">
                
                <p>可编程处理单元**（Graphic Processor Unit）<strong>日益发展成为高并行、多线程、多核处理的计算利器，2006年11月，NVIDIA推出了</strong>CUDA**——一种通用并行计算平台和编程模型，通过NVIDIA GPU中的并行计算引擎，以比CPU更高效的方式解决复杂的计算问题。</p>
<p>本文基于CUDA官方文档：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html">1. Preface — CUDA C++ Best Practices Guide 12.9 documentation</a></p>
<span id="more"></span>
<h2 id="GPU结构">GPU结构</h2>
<p>CPU和GPU在计算单元上存在以下的不同：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>组件</strong></th>
<th style="text-align:left"><strong>CPU</strong></th>
<th style="text-align:left"><strong>GPU</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>控制单元</strong></td>
<td style="text-align:left">1个强大的控制单元（Control）</td>
<td style="text-align:left">极简控制逻辑（图中未单独标注）</td>
</tr>
<tr>
<td style="text-align:left"><strong>ALU数量</strong></td>
<td style="text-align:left">少量复杂ALU（通常4-8核）</td>
<td style="text-align:left">大量简单ALU（数千个流处理器）</td>
</tr>
<tr>
<td style="text-align:left"><strong>线程能力</strong></td>
<td style="text-align:left">支持少量并行线程（超线程优化）</td>
<td style="text-align:left">支持数万并发线程</td>
</tr>
</tbody>
</table>
<p>CPU通过单个控制单元管理少量的ALU，GPU无集中标注的控制单元，突出多ALU（<strong>Arithmetic Logic Unit，算术逻辑单元</strong>）并行；此外CPU利用大容量多级缓存（L1/L2/L3）实现不同层级的信息缓存，GPU的共享缓存则很少量，两者都连接DRAM（<strong>Dynamic Random-Access Memory，动态随机存取存储器，用于临时存储计算机运行时所需的程序和数据，断电后数据丢失</strong>），但GPU的显存带宽通常是CPU的5-10倍。</p>
<p><img src="CPU%E5%92%8CGPU%E7%9A%84%E5%AF%B9%E6%AF%94.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="CPU和GPU的对比" /></p>
<p>总的来说，GPU通过<strong>高度并行运算</strong>，使用大量ALU组成流式多处理器（SM）来隐藏内存访问延迟，而不是像CPU一样利用大量的数据缓存和流控制来确保低延迟。</p>
<p>在CUDA并行编程中，有三个关键抽象为开发者提供高效的并行计算能力：</p>
<ol>
<li><strong>线程组层次结构（Hierarchy of Thread Groups）</strong></li>
<li><strong>共享内存（Shared Memory）</strong></li>
<li><strong>屏障同步（Barrier Synchronization）</strong></li>
</ol>
<p>线程组通过网格（Grid）、线程块（Block）、线程（Thread）的分层结构，利用共享内存<code>__shared__</code>进行快速数据交换，同时通过<code>__syncthreads()</code>确保数据的一致性，即块内所有的线程必须执行到当前点才能继续。</p>
<p><img src="%E5%85%B3%E9%94%AE%E6%8A%BD%E8%B1%A1%E7%9A%84%E5%85%B3%E7%B3%BB.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="关键抽象的关系" /></p>
<h2 id="CUDA编程模型">CUDA编程模型</h2>
<p>首先需要明白CUDA 编程中的<em><strong>kernels</strong></em>的概念，<em><strong>kernel</strong></em>可以理解为CUDA扩展的下的函数实现，以C++为例（本文都采用C++作为示例），常规C++函数往往只能按序执行一次，而在<em><strong>kernels</strong></em>下，这些函数调用由N个不同的CUDA线程并行执行N次。</p>
<p>内核使用 <code>__global__</code>说明符定义，使用<code>&lt;&lt;&lt;block数、每个block的thread数&gt;&gt;&gt;</code>指定总的CUDA线程数（总线程数：numBlocks * threadPerBlock）,执行<em><strong>kernel</strong></em>的每个线程都有一个唯一的线程ID，即<code>threadIdx</code>。</p>
<p><strong>threadIdx</strong>是一个可以包含三个维度的向量，可以通过下表中的计算公式获得：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>维度</strong></th>
<th style="text-align:left"><strong>全局索引公式</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1D</td>
<td style="text-align:left"><code>tid = blockIdx.x * blockDim.x + threadIdx.x</code></td>
</tr>
<tr>
<td style="text-align:left">2D</td>
<td style="text-align:left"><code>row = blockIdx.y * blockDim.y + threadIdx.y</code> <code>col = blockIdx.x * blockDim.x + threadIdx.x</code></td>
</tr>
<tr>
<td style="text-align:left">3D</td>
<td style="text-align:left"><code>x = blockIdx.x * blockDim.x + threadIdx.x</code> <code>y = blockIdx.y * blockDim.y + threadIdx.y</code> <code>z = blockIdx.z * blockDim.z + threadIdx.z</code></td>
</tr>
</tbody>
</table>
<ul>
<li><code>threadIdx.x</code>：线程在块内的 x 维索引（从 0 开始）</li>
<li><code>blockIdx.x</code>：块在网格中的 x 维索引</li>
<li><code>blockDim.x</code>：每个块的 x 维线程数</li>
<li><code>gridDim.x</code>：网格中 x 维的块数</li>
</ul>
<p>对于一维块，线程索引和ID是相同的;对于大小为 （Dx， Dy） 的二维块，索引为 （x， y） 的线程 ID 为 （x + y Dx）;对于大小为 （Dx， Dy， Dz） 的三维块，索引为 （x， y， z） 的线程ID 为 （x + y Dx + z Dx Dy），可通过上表联立计算threadIdx得到。</p>
<p><img src="Grid_Block_Thread.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="Grid_Block_Thread" /></p>
<p>同样的，通过<code>blockIdx</code>确定block所在的索引（可以理解为行），<code>blockDim</code>确定对应的维度，值得注意的是</p>
<p><code>&lt;&lt;&lt;…&gt;&gt;&gt;</code>可以被指定为int 或者是 <code>dim3</code>，用于表示二维块或者网格。</p>
<p>以下看几个具体的编程示例:</p>
<p><strong>两个一维的数组相加</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">VecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> i = theadIdx.x; <span class="hljs-comment">//应为blockIdx.x + blockDim.x + threadIdx.x 但是此处block数为1</span><br>    C[i] = A[i] + B[i];<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    ...<br>    VecAdd&lt;&lt;&lt;<span class="hljs-number">1</span>, N&gt;&gt;&gt;(A, B, C);    <br>    ...<br>&#125;<br></code></pre></td></tr></table></figure>
<p><strong>两个二维数组相加</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatAdd</span><span class="hljs-params">(<span class="hljs-type">float</span> A[N][N], <span class="hljs-type">float</span> B[N][N], <span class="hljs-type">float</span> C[N][N])</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> i = threadIdx.x; <span class="hljs-comment">//此处应为blockIdx.x * blockDim.x + threadIdx.x</span><br>    <span class="hljs-type">int</span> j = threadIdx.y; <span class="hljs-comment">//此处应为blockIdx.y * blockDim.y + threadIdx.y 但是block为1</span><br>    c[i][j] = A[i][j] + B[i][j];<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> numBlocks = <span class="hljs-number">1</span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(N,N)</span></span>;<br>    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B. C);<br>&#125;<br></code></pre></td></tr></table></figure>
<p><strong>更为一般的情况</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatAdd</span><span class="hljs-params">(<span class="hljs-type">float</span> A[N][N], <span class="hljs-type">float</span> B[N][N], <span class="hljs-type">float</span> C[N][N])</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-keyword">if</span>(i &lt; N ** j &lt; N)<br>    	c[i][j] = A[i][j] + B[i][j];<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-function">dim3 <span class="hljs-title">threadsPerBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>,<span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">numBlocks</span><span class="hljs-params">(N / threadsPerBlock.x, N / threadPerBlock.y)</span></span>;<br>    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B. C);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>在边缘端设备Jetson Orin Nano 8G、Cuda-11.4运行<code>hello.cu</code></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span><span class="hljs-comment">//它声明了你在 CUDA kernel 函数中会使用的一些 内置变量</span></span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">kernel</span><span class="hljs-params">()</span> </span>&#123;<br>	<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello world&quot;</span>);<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>	kernel &lt;&lt;&lt;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>&gt;&gt;&gt; ();<br>	cudaError_t err = <span class="hljs-built_in">cudaDeviceSynchronize</span>();<br>	<span class="hljs-keyword">if</span> (err != cudaSuccess) &#123;<br>		std::cerr &lt;&lt; <span class="hljs-string">&quot;CUDA Error: &quot;</span> &lt;&lt; <span class="hljs-built_in">cudaGetErrorString</span>(err) &lt;&lt; std::endl;<br>	&#125;<br> <br>	<span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc hello.cu  -o hello<br><br>./hello<br>hello world<br></code></pre></td></tr></table></figure>
<h2 id="CUDA内存结构">CUDA内存结构</h2>
<p>CUDA线程在执行期间会访问到来自多个内存空间的数据，值得注意的是：</p>
<ul>
<li>每个线程都有自己独立的<strong>私有内存</strong>（类似于进程中线程的独立栈空间）</li>
<li>同一个线程块中含有<strong>共享内存（shared memory）</strong>，对该块中的所有线程可见，同时与该块具有相同的生命周期</li>
<li>除此之外，所有线程都可以访问相同的**全局内存（global memory）**以及只读的内存空间：<strong>常量内存（constant memory）<strong>和</strong>纹理内存（texture memory）</strong></li>
</ul>
<p><img src="%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="内存结构" /></p>
<p>当执行一个C++程序时，其中的线性化流程会在<strong>Host（主设备）<strong>上运行，其余的可以并行的程序将会在一个个独立的</strong>Device（从设备）<strong>上运行（例如</strong>kernel</strong>），<em><strong>CUDA runtime</strong></em>用于管理<strong>kernel</strong>可见的全局内存、常量内存以及纹理内存，同时负责device的内存分配和释放，以及<strong>host</strong>与<strong>device</strong>之间的数据传输。</p>
<p>不同的GPU设备具备不同的计算能力，称之为“SM version”, NVIDIA GPU架构全览如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>架构名称</strong></th>
<th style="text-align:left"><strong>发布时间</strong></th>
<th style="text-align:left"><strong>计算能力 (SM)</strong></th>
<th style="text-align:left"><strong>代表产品</strong></th>
<th style="text-align:left"><strong>制程工艺</strong></th>
<th style="text-align:left"><strong>核心创新</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Tesla</strong></td>
<td style="text-align:left">2006</td>
<td style="text-align:left">SM 1.x</td>
<td style="text-align:left">GeForce 8800 GTX</td>
<td style="text-align:left">90nm</td>
<td style="text-align:left">首款支持CUDA的架构</td>
</tr>
<tr>
<td style="text-align:left"><strong>Fermi</strong></td>
<td style="text-align:left">2010</td>
<td style="text-align:left">SM 2.x</td>
<td style="text-align:left">GTX 480, Tesla C2050</td>
<td style="text-align:left">40nm</td>
<td style="text-align:left">首次支持FP64、ECC显存、L1/L2缓存</td>
</tr>
<tr>
<td style="text-align:left"><strong>Kepler</strong></td>
<td style="text-align:left">2012</td>
<td style="text-align:left">SM 3.x</td>
<td style="text-align:left">GTX 680, Tesla K80</td>
<td style="text-align:left">28nm</td>
<td style="text-align:left">动态并行、Hyper-Q、GPU Boost</td>
</tr>
<tr>
<td style="text-align:left"><strong>Maxwell</strong></td>
<td style="text-align:left">2014</td>
<td style="text-align:left">SM 5.x</td>
<td style="text-align:left">GTX 980, Tesla M40</td>
<td style="text-align:left">28nm</td>
<td style="text-align:left">SMM设计、能效比提升2倍</td>
</tr>
<tr>
<td style="text-align:left"><strong>Pascal</strong></td>
<td style="text-align:left">2016</td>
<td style="text-align:left">SM 6.x</td>
<td style="text-align:left">GTX 1080 Ti, Tesla P100</td>
<td style="text-align:left">16nm</td>
<td style="text-align:left">NVLink 1.0、FP16支持、HBM2显存</td>
</tr>
<tr>
<td style="text-align:left"><strong>Volta</strong></td>
<td style="text-align:left">2017</td>
<td style="text-align:left">SM 7.0/7.2</td>
<td style="text-align:left">Tesla V100, Titan V</td>
<td style="text-align:left">12nm</td>
<td style="text-align:left">首代Tensor Core、独立线程调度</td>
</tr>
<tr>
<td style="text-align:left"><strong>Turing</strong></td>
<td style="text-align:left">2018</td>
<td style="text-align:left">SM 7.5</td>
<td style="text-align:left">RTX 2080 Ti, Tesla T4</td>
<td style="text-align:left">12nm</td>
<td style="text-align:left">RT Core、第二代Tensor Core（INT8/INT4）、GDDR6</td>
</tr>
<tr>
<td style="text-align:left"><strong>Ampere</strong></td>
<td style="text-align:left">2020</td>
<td style="text-align:left">SM 8.x</td>
<td style="text-align:left">RTX 3090, Tesla A100</td>
<td style="text-align:left">7nm/8nm</td>
<td style="text-align:left">第三代Tensor Core（TF32）、MIG、结构化稀疏</td>
</tr>
<tr>
<td style="text-align:left"><strong>Hopper</strong></td>
<td style="text-align:left">2022</td>
<td style="text-align:left">SM 9.x</td>
<td style="text-align:left">H100</td>
<td style="text-align:left">4nm</td>
<td style="text-align:left">第四代Tensor Core（FP8）、Transformer引擎、机密计算</td>
</tr>
<tr>
<td style="text-align:left"><strong>Ada Lovelace</strong></td>
<td style="text-align:left">2022</td>
<td style="text-align:left">SM 8.9</td>
<td style="text-align:left">RTX 4090</td>
<td style="text-align:left">5nm</td>
<td style="text-align:left">DLSS 3、光追性能翻倍、AV1编码</td>
</tr>
<tr>
<td style="text-align:left"><strong>Blackwell</strong></td>
<td style="text-align:left">2024*</td>
<td style="text-align:left">SM 10.x*</td>
<td style="text-align:left">B100 (预计)</td>
<td style="text-align:left">3nm*</td>
<td style="text-align:left">FP6支持、新一代NVLink*（*为预测特性）</td>
</tr>
</tbody>
</table>
<p>可以通过在代码中嵌入如下命令显示对应的 “SM_version”</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++">cudaDeviceProp prop;<br><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Arch: SM_%d%d\n&quot;</span>, prop.major, prop.minor);<br><br><span class="hljs-comment">//Jetson Orin Nano 8G</span><br>jetson@unbutu:~/mhj/CUDA_ws$ ./hello <br>Arch: SM_87<br></code></pre></td></tr></table></figure>
<h2 id="CUDA编程接口">CUDA编程接口</h2>
<p>CUDA C++由<strong>C++ Language Extensions</strong> 和 <strong>CUDA Runtime</strong>组成，其中<strong>C++ Language Extensions</strong>即C++形式下的CUDA编程模型，例如C++形式下的<strong>kernels</strong>，而<strong>CUDA Runtime</strong> 则用于更底层的功能，运行在更低级的API上，例如在<strong>host</strong> 和 device之间传输数据，分配和释放内存，管理多个<strong>device</strong>等，往往使用C 和 C++混合实现。</p>
<h3 id="NVCC编译">NVCC编译</h3>
<p>NVCC的编译过程分为两个主要阶段：</p>
<ul>
<li><strong>主机代码(Host Code)处理</strong>：处理CPU端的C++代码</li>
<li><strong>设备代码(Device Code)处理</strong>：处理GPU端的CUDA代码</li>
</ul>
<p>主要分为以下几个阶段：</p>
<ul>
<li><strong>预处理阶段</strong>：首先调用C/C++预处理器处理<code>.cu</code>文件，处理所有<code>#include</code>、<code>#define</code>等预处理指令，展开宏定义。</li>
<li><strong>代码分离</strong>：NVCC将代码分离为主机代码和设备代码，主机代码即普通的C++代码，由CPU执行，设备代码，即标记有<code>__global__</code>、<code>__device__</code>等限定符的函数，由GPU执行。</li>
<li><strong>设备代码编译</strong>：使用NVIDIA的专有编译器前端和后端将设备代码编译为PTX(Parallel Thread eXecution)虚拟汇编代码，或者是直接编译为cubin二进制格式(使用<code>-cubin</code>选项)。</li>
<li><strong>主机代码编译</strong>：生成修改过的主机代码，其中包含对CUDA Runtime API的调用，传递给系统的C++编译器(如gcc、clang等)</li>
<li><strong>链接阶段</strong>：将所有对象文件(主机和设备)链接在一起，链接CUDA运行时库，生成最终的可执行文件。</li>
</ul>
<p>编译时有如下选项：</p>
<ul>
<li><code>--cuda</code>：只生成主机代码，不进行设备代码编译</li>
<li><code>-ptx</code>：只生成PTX代码</li>
<li><code>-cubin</code>：生成cubin二进制文件</li>
<li><code>-fatbin</code>：生成fatbin文件(包含多种架构的二进制)</li>
<li><code>-keep</code>：保留中间文件用于调试</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc -<span class="hljs-built_in">arch</span>=sm_75 -o my_program myprogram.cu<br><br>-<span class="hljs-built_in">arch</span>=sm_75 是 -gencode <span class="hljs-built_in">arch</span>=compute_35,code= \&#x27;compute_35,sm_35\&#x27; 的简写<br>也是 -gencode <span class="hljs-built_in">arch</span>=compute_35,code=sm_35的简写<br></code></pre></td></tr></table></figure>
<p><strong>Just-In-Time (JIT)</strong> 编译是一种动态编译技术，它在程序运行时(而非之前)将代码编译为机器指令。这种技术结合了解释执行的灵活性和预先编译(AOT, Ahead-Of-Time)的高效性。CUDA中的JIT编译将PTX代码在运行时编译为特定GPU的机器码，允许代码在不同代GPU上运行。</p>
<p>在CUDA中，JIT编译通常发生在：</p>
<ol>
<li>应用程序加载PTX代码时</li>
<li>驱动程序将PTX即时编译为当前GPU的特定机器码</li>
<li>缓存编译结果供后续使用</li>
</ol>
<h3 id="CUDA-Runtime">CUDA Runtime</h3>
<p>CUDA Runtime由<code>cudart</code>库实现，cudart库通过<code>cudart.lib</code>和<code>libcudart.a</code>静态链接，或者由<code>cudart.dll</code>或<code>libcudart.so</code>动态链接。</p>
<p>CUDA Runtime在第一次调用Runtime function时进行初始化，不显式初始化，在初始化期间，Runtime会为系统中的每个设备创建一个CUDA上下文，CUDA 上下文是指GPU 上的虚拟执行环境，包含所有 GPU 状态（内存、模块、流等）的容器，类似于 CPU 编程中的进程概念。</p>
<p>使用Runtime API隐式的创建上下文</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">cudaMalloc</span>(&amp;devPtr, size); <span class="hljs-comment">// 第一次调用Runtime API时会自动创建上下文</span><br></code></pre></td></tr></table></figure>
<h3 id="Device-Memory">Device Memory</h3>
<p>每个Host和Device都有自己独立的内存，Runtime提供分配释放Host memory和Device memory以及二者之间数据的传输。</p>
<p>Device memory 可以进一步分配为 linear memory 和 CUDA arrays，CUDA arrays是不透明的内存布局，而linear memory则被分配到一个统一的地址空间中。</p>
<p>linear memory通过 <code>cudaMalloc()</code>分配，<code>cudaFree()</code>释放，利用<code>cudaMemcpy()</code>进行host memory和device memory之间的数据传输。</p>
<p>下列命令实现了在Device 空间做运算，最后将device空间的数据拷贝到host空间</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span><span class="hljs-comment">//它声明了你在 CUDA kernel 函数中会使用的一些 内置变量</span></span><br><br><span class="hljs-comment">//device code</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">vecAdd</span><span class="hljs-params">(<span class="hljs-type">float</span>* A, <span class="hljs-type">float</span>* B, <span class="hljs-type">float</span>* C, <span class="hljs-type">int</span> N)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;<br>    <span class="hljs-keyword">if</span>( i &lt; N)<br>        C[i] = A[i] + B[i];<br>&#125; <br><br><span class="hljs-comment">//host code</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> N = <span class="hljs-number">16</span>;<br>    <span class="hljs-type">size_t</span> size = N * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>    <span class="hljs-comment">//host memory </span><br>    <span class="hljs-type">float</span>* h_A = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_B = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-type">float</span>* h_C = (<span class="hljs-type">float</span>*)<span class="hljs-built_in">malloc</span>(size);<br>    <span class="hljs-comment">/******</span><br><span class="hljs-comment">     * 初始化输入矩阵</span><br><span class="hljs-comment">     */</span><br><br>    <span class="hljs-comment">//device memory</span><br>    <span class="hljs-type">float</span>* d_A;<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A, size);<br>    <span class="hljs-type">float</span>* d_B;<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B, size);<br>    <span class="hljs-type">float</span>* d_C;<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C, size);<br><br>    <span class="hljs-comment">//copy data from host to device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);<br><br>    <span class="hljs-comment">//kernel</span><br>    <span class="hljs-type">int</span> threadsPerBlock = <span class="hljs-number">256</span>;<br>    <span class="hljs-type">int</span> blocksPerGrid = <br>    (N + threadsPerBlock - <span class="hljs-number">1</span>) / threadsPerBlock;<br><br>    vecAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);<br><br>    <span class="hljs-comment">//copy data from device to host</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);<br><br>    <span class="hljs-comment">//free device memory</span><br>    <span class="hljs-built_in">cudaFree</span>(d_A);<br>    <span class="hljs-built_in">cudaFree</span>(d_B);<br>    <span class="hljs-built_in">cudaFree</span>(d_C);<br><br>    <span class="hljs-comment">/***</span><br><span class="hljs-comment">     * free host memory</span><br><span class="hljs-comment">     */</span><br><br>&#125;<br></code></pre></td></tr></table></figure>
<p>进一步的，可以通过<code>cudaMallocPitch()</code> 和 <code>cudaMalloc3D()</code> 分配2D和3D的数组（对应的数据复制可以使用<code>cudaMemcpy2D()</code> 和 <code>cudaMemcpy3D()</code>）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMallocPitch</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">void</span>** devPtr,      <span class="hljs-comment">// 输出参数，返回分配的内存地址指针</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span>* pitch,      <span class="hljs-comment">// 输出参数，返回实际分配的行间距（字节数）</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> width,       <span class="hljs-comment">// 请求分配的每行宽度（字节数）</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> height,      <span class="hljs-comment">// 请求分配的行数</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> elementSize  <span class="hljs-comment">// 可选参数，元素大小（默认为1，CUDA 12.0+新增）</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMalloc3D</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    cudaPitchedPtr* pitchedDevPtr,  <span class="hljs-comment">// 输出参数，返回分配的内存信息</span></span></span><br><span class="hljs-params"><span class="hljs-function">    cudaExtent extent               <span class="hljs-comment">// 请求分配的3D空间范围</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaExtent</span> &#123;<br>    <span class="hljs-type">size_t</span> width;   <span class="hljs-comment">// 宽度（字节数）</span><br>    <span class="hljs-type">size_t</span> height;  <span class="hljs-comment">// 高度（元素行数）</span><br>    <span class="hljs-type">size_t</span> depth;   <span class="hljs-comment">// 深度（切片数）</span><br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaPitchedPtr</span> &#123;<br>    <span class="hljs-type">void</span>* ptr;      <span class="hljs-comment">// 内存指针</span><br>    <span class="hljs-type">size_t</span> pitch;   <span class="hljs-comment">// 行间距（字节数）</span><br>    <span class="hljs-type">size_t</span> xsize;   <span class="hljs-comment">// 实际分配的宽度</span><br>    <span class="hljs-type">size_t</span> ysize;   <span class="hljs-comment">// 实际分配的高度</span><br>&#125;;<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span></span><br><br><span class="hljs-comment">//device code</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">Mykernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* devPtr, <span class="hljs-type">size_t</span> pitch, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> r = <span class="hljs-number">0</span>; r &lt; height; ++r)<br>    &#123;<br>        <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)((<span class="hljs-type">char</span>*)devPtr + r * pitch);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> c = <span class="hljs-number">0</span>; c &lt; width; ++c)<br>            <span class="hljs-type">int</span> element = row[c];<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">//host code</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>;<br>    <span class="hljs-type">float</span>* devPtr;<br>    <span class="hljs-type">size_t</span> pitch;<br><br>    <span class="hljs-built_in">cudaMallocPitch</span>(&amp;devPtr, &amp;pitch, width, height);<br><br>    Mykernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPtr, pitch, width, height);<br>&#125;<br></code></pre></td></tr></table></figure>
<p><img src="3D%E7%BB%93%E6%9E%84.jpg" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="3D结构" /></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span></span><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">Mykernel</span><span class="hljs-params">(cudaPitchedPtr devPitchPtr,</span></span><br><span class="hljs-params"><span class="hljs-function">                    <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height, <span class="hljs-type">int</span> depth)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">char</span>* devPtr = (<span class="hljs-type">char</span>*)devPitchPtr.ptr;<br>    <span class="hljs-type">size_t</span> pitch = devPitchPtr.pitch;<br>    <span class="hljs-type">size_t</span> slicePitch = height * pitch;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> z = <span class="hljs-number">0</span>; z &lt; depth; ++z)<br>    &#123;<br>        <span class="hljs-type">char</span>* slice = devPtr + z*slicePitch;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> y = <span class="hljs-number">0</span>; y &lt; height; ++y)<br>        &#123;<br>            <span class="hljs-type">float</span>* row = (<span class="hljs-type">float</span>*)(slice + y* pitch);<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x = <span class="hljs-number">0</span>; x &lt; width; ++x)<br>                <span class="hljs-type">float</span> element = row[x];<br>        &#125;<br>    &#125;<br><br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> width = <span class="hljs-number">64</span>, height = <span class="hljs-number">64</span>, depth = <span class="hljs-number">64</span>;<br>    cudaExtent extent = <span class="hljs-built_in">make_cudaExtent</span>(width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height, depth);<br><br>    cudaPitchedPtr devPitchedPtr;<br>    <span class="hljs-built_in">cudaMalloc3D</span>(&amp;devPitchedPtr, extent);<br><br>    Mykernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>&gt;&gt;&gt;(devPitchedPtr, width, height, depth);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>有如下的变量声明</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">__device__ <span class="hljs-type">float</span> devData; <span class="hljs-comment">//设备端(Device)的全局变量</span><br>__constant__ <span class="hljs-type">float</span> constData; <span class="hljs-comment">//只读且缓存</span><br>__shared__ <span class="hljs-type">float</span> sharedData;  <span class="hljs-comment">// 更快但块内可见</span><br></code></pre></td></tr></table></figure>
<p>使用 <code>cudaMemcpyToSymbol</code>将host内存拷贝到device端</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMemcpyToSymbol</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">void</span>* symbol, <span class="hljs-comment">// 设备端的符号(通常是全局变量或常量)</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">void</span>* src,    <span class="hljs-comment">// 主机端源数据指针</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> count,       <span class="hljs-comment">// 要拷贝的字节数</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> offset = <span class="hljs-number">0</span>,  <span class="hljs-comment">// 可选参数，符号地址的偏移量(默认为0)</span></span></span><br><span class="hljs-params"><span class="hljs-function">    cudaMemcpyKind kind = cudaMemcpyHostToDevice <span class="hljs-comment">// 拷贝方向</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br></code></pre></td></tr></table></figure>
<p>使用 <code>cudaMemcpyFromSymbol</code>将device侧拷贝到host内存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaMemcpyFromSymbol</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">void</span>* dst,          <span class="hljs-comment">// 主机端目标指针</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">const</span> <span class="hljs-type">void</span>* symbol, <span class="hljs-comment">// 设备端的符号</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> count,       <span class="hljs-comment">// 要拷贝的字节数</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">size_t</span> offset = <span class="hljs-number">0</span>,  <span class="hljs-comment">// 可选参数，符号地址的偏移量(默认为0)</span></span></span><br><span class="hljs-params"><span class="hljs-function">    cudaMemcpyKind kind = cudaMemcpyDeviceToHost <span class="hljs-comment">// 拷贝方向</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br></code></pre></td></tr></table></figure>
<h3 id="Shared-Memory">Shared Memory</h3>
<p>共享内存使用<code>__shared__</code>说明符实现，其速度比全局内存快得多，下面代码是一个矩阵乘法的实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span></span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span><br>&#123;<br>    <span class="hljs-type">int</span> width;<br>    <span class="hljs-type">int</span> height;<br>    <span class="hljs-type">float</span>* elements;<br><br>&#125; Matrix;<br><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-comment">//Forward declaration</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulkernel</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix, <span class="hljs-type">const</span> Matrix, Matrix)</span></span>;<br><br><br><span class="hljs-comment">//Host code</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">MatMul</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">const</span> Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>&#123;<br>    Matrix d_A;<br>    d_A.width = A.width; d_A.height = A.height;<br>    <span class="hljs-type">size_t</span> size = A.width * A.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A.elements, size);<br>    <span class="hljs-comment">//host to device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A.elements, A.elements, size, cudaMemcpyHostToDevice);<br><br>    Matrix d_B;<br>    d_B.width = B.width, d_B.height = B.height;<br>    size = B.width * B.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B.elements, size);<br>    <span class="hljs-comment">//host to device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B.elements, B.elements, size, cudaMemcpyHostToDevice);<br><br><br>    Matrix d_C;<br>    d_C.width = C.width, d_C.height = C.height;<br>    size = C.width * C.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-comment">//only need to malloc memory in device </span><br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C.elements, size);<br><br>    <span class="hljs-function">dim3 <span class="hljs-title">dimBlock</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">dimGrid</span><span class="hljs-params">(B.width / BLOCK_SIZE, A.height / BLOCK_SIZE)</span></span>;<br><br>    MatMulkernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C);<br><br>    <span class="hljs-comment">//read C from device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(C.elements, d_C.elements, size, cudaMemcpyDeviceToHost);<br><br><br>    <span class="hljs-built_in">cudaFree</span>(d_A.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_B.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_C.elements);<br>&#125;<br><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulkernel</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">const</span> Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">float</span> Cvalue = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">int</span> row = blockDim.y * blockIdx.y + threadIdx.y;<br>    <span class="hljs-type">int</span> col = blockDim.x * blockIdx.x + threadIdx.x;<br><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; A.width; ++i)<br>    &#123;<br>        Cvalue += A.elements[row * A.width + i] * B.elements[i * B.width + col];<br>    &#125;<br>    C.elements[row * C.width + col] = Cvalue;<br>&#125;<br><br></code></pre></td></tr></table></figure>
<p><img src="Matrix_Multiplication.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="Matrix_Multiplication" /></p>
<p>进一步采用共享内存优化，将大矩阵分解为 <code>BLOCK_SIZE × BLOCK_SIZE</code> 的子矩阵，每个线程块计算一个子矩阵 <code>Csub</code>，每个线程计算 <code>Csub</code> 的一个元素，<code>As</code> 和 <code>Bs</code> 存储在共享内存中，减少对全局内存的访问，每个线程块只需加载 <code>Asub</code> 和 <code>Bsub</code> 一次，然后所有线程共享这些数据。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> BLOCK_SIZE 16</span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-keyword">struct</span><br>&#123;<br>    <span class="hljs-type">int</span> width;<br>    <span class="hljs-type">int</span> height;<br>    <span class="hljs-type">int</span> stride; <span class="hljs-comment">/// 矩阵的内存步长（通常等于width, 表示一行有多少个元素）</span><br>    <span class="hljs-type">float</span> * elements;<br>&#125; Matrix;<br><br><span class="hljs-comment">//Get matrix element in[row, col]</span><br><span class="hljs-function">__device__ <span class="hljs-type">float</span> <span class="hljs-title">GetElement</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">return</span> A.elements[row * A.stride + col];<br>&#125;<br><br><span class="hljs-comment">//Set matrix element in[row,col]</span><br><span class="hljs-function">__device__ <span class="hljs-type">void</span> <span class="hljs-title">SetElement</span><span class="hljs-params">(Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col, <span class="hljs-type">float</span> value)</span></span><br><span class="hljs-function"></span>&#123;<br>    A.elements[row * A.stride + col] = value;<br>&#125;<br><br><span class="hljs-comment">//Get subMatrix in [row, col] (row col describe block not element)</span><br><span class="hljs-function">__device__ Matrix <span class="hljs-title">GetSubMatrix</span><span class="hljs-params">(Matrix A, <span class="hljs-type">int</span> row, <span class="hljs-type">int</span> col)</span></span><br><span class="hljs-function"></span>&#123;<br>    Matrix Asub;<br>    Asub.width = BLOCK_SIZE;<br>    Asub.height = BLOCK_SIZE;<br>    Asub.stride = A.stride;<br>    Asub.elements = &amp;A.elements[A.stride * row * BLOCK_SIZE + BLOCK_SIZE * col];<br><br>    <span class="hljs-keyword">return</span> Asub;<br>&#125;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulkernel</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix, <span class="hljs-type">const</span> Matrix, Matrix)</span></span>;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">MatMul</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">const</span> Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>&#123;<br>    Matrix d_A;<br>    d_A.width = d_A.stride = A.width; d_A.height = A.height;<br>    <span class="hljs-type">size_t</span> size = d_A.width * d_A.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_A.elements, size);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_A.elements, A.elements, size, cudaMemcpyHostToDevice);<br><br><br>    Matrix d_B;<br>    d_B.width = d_B.stride = B.width; d_B.height = B.height;<br>    <span class="hljs-type">size_t</span> size = d_B.width * d_B.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_B.elements, size);<br>    <span class="hljs-built_in">cudaMemcpy</span>(d_B.elements, B.elements, size, cudaMemcpyHostToDevice);<br><br><br>    Matrix d_C;<br>    d_C.width = d_C.stride = C.width; d_C.height = C.height;<br>    <span class="hljs-type">size_t</span> size = d_C.width * d_C.height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;d_C.elements, size);<br><br>    <span class="hljs-function">dim3 <span class="hljs-title">dimBlock</span><span class="hljs-params">(BLOCK_SIZE, BLOCK_SIZE)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">dimGrid</span><span class="hljs-params">(B.width / BLOCK_SIZE, A.height / BLOCK_SIZE)</span></span>;<br><br>    MatMulkernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_A, d_B, d_C);<br><br>    <span class="hljs-comment">//read C from device</span><br>    <span class="hljs-built_in">cudaMemcpy</span>(C.elements, d_C.elements, size, cudaMemcpyDeviceToHost);<br><br><br>    <span class="hljs-built_in">cudaFree</span>(d_A.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_B.elements);<br>    <span class="hljs-built_in">cudaFree</span>(d_C.elements);<br>    <br>&#125;<br><br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MatMulkernel</span><span class="hljs-params">(<span class="hljs-type">const</span> Matrix A, <span class="hljs-type">const</span> Matrix B, Matrix C)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> blockRow = blockDim.y;<br>    <span class="hljs-type">int</span> blockCol = blockDim.x;<br><br>    <span class="hljs-comment">//Each Block computes one sub-matrix of C</span><br>    Matrix Csub = <span class="hljs-built_in">GetSubMatrix</span>(C, blockRow, blockCol);<br><br>    <span class="hljs-comment">//Thread row and col in Csub</span><br>    <span class="hljs-type">int</span> row = threadIdx.y;<br>    <span class="hljs-type">int</span> col = threadIdx.x;<br><br>    <span class="hljs-comment">//Each thread computes one element of Csub</span><br>    <span class="hljs-type">float</span> Cvalue = <span class="hljs-number">0</span>;<br><br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> m = <span class="hljs-number">0</span>; m &lt; (A.width / BLOCK_SIZE); ++m)<br>    &#123;<br>        Matrix Asub = <span class="hljs-built_in">GetSubMatrix</span>(A, blockRow, m);<br>        Matrix Bsub = <span class="hljs-built_in">GetSubMatrix</span>(B, m, blockCol);<br><br>        <span class="hljs-comment">//shared_memory to store Asub and Bsub</span><br>        __shared__ <span class="hljs-type">float</span> As[BLOCK_SIZE][BLOCK_SIZE];<br>        __shared__ <span class="hljs-type">float</span> Bs[BLOCK_SIZE][BLOCK_SIZE];<br><br>        As[row][col] = <span class="hljs-built_in">GetElement</span>(A, row, col);<br>        Bs[row][col] = <span class="hljs-built_in">GetElement</span>(B, row, col);<br><br>        <span class="hljs-comment">//确保上述所有操作同步</span><br>        __syncthreads();<br><br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> e = <span class="hljs-number">0</span>; e &lt; BLOCK_SIZE; e++)<br>            Cvalue += As[row][e] * Bs[e][col];<br><br>        <br>        __syncthreads();<br>    &#125;<br><br>    <span class="hljs-built_in">SetElement</span>(C, row, col, Cvalue);<br>&#125;<br><br></code></pre></td></tr></table></figure>
<p>值得注意的是 <code>GetSubMatrix()</code>的逻辑，其中的<code>[row,col]</code>是以整个<strong>Block</strong>为单位，而不再是以单个element为单元, 同时矩阵的宽度和高度必须是 <code>BLOCK_SIZE</code> 的整数倍。</p>
<p><img src="subMatrix.jpg" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="subMatrix" /></p>
<p><img src="Shared_memory.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="Shared_memory" /></p>
<h3 id="Page-Locked-Host-Memory（页锁定主机内存）">Page-Locked Host Memory（页锁定主机内存）</h3>
<p>Page-Locked Host Memory（也称为 <strong>Pinned Memory</strong> 或 <strong>Non-Pageable Memory</strong>）是 CUDA 中一种特殊的主机（CPU）内存分配方式，它<strong>禁止操作系统对这块内存进行分页交换（Page-Out）</strong>，从而保证内存始终驻留在物理 RAM 中，不会因虚拟内存机制被换出到磁盘.</p>
<p>在默认情况下，主机内存是 <strong>Pageable（可分页的）</strong>，操作系统可以随时将不活跃的内存页换出到磁盘（Swap Space）。但在 GPU 计算中，这会带来两个问题：</p>
<ol>
<li><strong>异步内存拷贝的效率问题</strong>
<ul>
<li>CUDA 的 <code>cudaMemcpy</code> 默认是同步操作，但如果使用 <code>cudaMemcpyAsync</code>（异步拷贝），要求源或目标内存必须是 <strong>Page-Locked</strong>，否则无法保证 DMA（直接内存访问）的正确性。</li>
<li>如果内存可分页，GPU 驱动必须先临时锁定内存，再执行拷贝，这会降低性能。</li>
</ul>
</li>
<li><strong>零拷贝内存（Zero-Copy）支持</strong>
<ul>
<li>Page-Locked Memory 可以直接映射到 GPU 地址空间，允许 GPU 直接访问主机内存（避免显式拷贝），但要求内存必须是锁定的</li>
</ul>
</li>
</ol>
<p>所以页锁主机内存适用于<strong>频繁的 CPU-GPU 数据传输</strong>（如深度学习数据加载），<strong>异步内存拷贝（<code>cudaMemcpyAsync</code>）</strong>，以及<strong>Zero-Copy 内存（GPU 直接访问主机内存）</strong></p>
<p>使用<code>cudaHostAlloc</code> 、<code>cudaFreeHost</code> 进行分配和释放内存</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">float</span> *h_data;<br><span class="hljs-built_in">cudaHostAlloc</span>((<span class="hljs-type">void</span>**)&amp;h_data, size_in_bytes, cudaHostAllocDefault);<br><span class="hljs-comment">// ... 使用 h_data ...</span><br><span class="hljs-built_in">cudaFreeHost</span>(h_data);<br></code></pre></td></tr></table></figure>
<p><code>cudaHostAlloc</code>有如下的几个选项：</p>
<ol>
<li>
<p><strong>可移植内存（Portable Memory）</strong></p>
<p>Page-Locked内存通常仅对分配时当前的GPU设备有效，通过<code>cudaHostAllocPortable</code>标志分配的内存可被系统中<strong>所有GPU设备</strong>直接使用，适用于多GPU环境。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 分配可移植的Page-Locked内存</span><br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;h_portable, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaHostAllocPortable);<br><br><span class="hljs-comment">// 在多个设备上使用</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> dev = <span class="hljs-number">0</span>; dev &lt; num_devices; dev++) &#123;<br>    <span class="hljs-built_in">cudaSetDevice</span>(dev);<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(d_data[dev], h_portable, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice, stream[dev]);<br>&#125;<br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>写合并内存（Write-Combining Memory）</strong></p>
<p>Page-Locked内存通常是<strong>可缓存的</strong>（Cacheable），会占用CPU的L1/L2缓存,通过<code>cudaHostAllocWriteCombined</code>分配的内存为<strong>写合并内存</strong>，释放L1/L2缓存资源供其他应用使用，适用于主机频繁写入、GPU读取的数据（如实时数据采集）。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 分配Write-Combining内存（仅主机写入）</span><br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;h_wc, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaHostAllocWriteCombined);<br><br><span class="hljs-comment">// 主机填充数据（快速）</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++) h_wc[i] = data[i];<br><br><span class="hljs-comment">// 传输到GPU（高效）</span><br><span class="hljs-built_in">cudaMemcpyAsync</span>(d_data, h_wc, N*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice, stream);<br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>映射内存（Mapped Memory）</strong></p>
<p>利用<strong>零拷贝（Zero-Copy）</strong>，实现主机内存直接映射到GPU地址空间，无需显式拷贝。</p>
<p>主机地址：通过<code>cudaHostAlloc</code>返回。</p>
<p>设备地址：通过<code>cudaHostGetDevicePointer</code>获取。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">float</span> *h_mapped;<br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;h_mapped, size, cudaHostAllocMapped);<br><br><span class="hljs-type">float</span> *d_mapped;<br><span class="hljs-built_in">cudaHostGetDevicePointer</span>(&amp;d_mapped, h_mapped, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure>
<p>内核访问时自动触发传输，无需<code>cudaMemcpy</code>, 同时确保了数据传输与内核计算自动并行。</p>
<h3 id="异步并发执行">异步并发执行</h3>
<p>CUDA将以下操作视为独立任务，可并行执行：</p>
<ul>
<li><strong>主机计算</strong>（CPU任务）</li>
<li><strong>设备计算</strong>（GPU内核）</li>
<li><strong>主机→设备内存传输</strong>（H2D）</li>
<li><strong>设备→主机内存传输</strong>（D2H）</li>
<li><strong>设备内内存传输</strong>（D2D）</li>
<li><strong>多设备间内存传输</strong></li>
</ul>
<ol>
<li>
<p><strong>Host与Device并发执行</strong></p>
<p><strong>异步函数</strong>：通过非阻塞调用（如<code>cudaMemcpyAsync</code>、<code>kernel&lt;&lt;&lt;...&gt;&gt;&gt;</code>）让主机线程立即返回，无需等待设备完成。</p>
<p>注：<code>cudaMemcpyAsync</code> 是 CUDA 中用于<strong>异步内存拷贝</strong>的核心函数，它的主要作用是在<strong>不阻塞主机（CPU）线程</strong>的情况下，在主机（Host）与设备（Device）之间或设备内部传输数据。与同步版本的 <code>cudaMemcpy</code> 不同，<code>cudaMemcpyAsync</code> 允许 CPU 在数据传输的同时继续执行其他任务，从而实现<strong>计算与传输的重叠</strong>，提升程序的整体效率。</p>
</li>
<li>
<p><strong>并发内核执行</strong></p>
<p>设备需<strong>Compute Capability ≥ 2.0</strong>，且<code>concurrentKernels</code>属性为1。</p>
<ul>
<li>
<p><strong>上下文隔离</strong>：不同CUDA上下文的内核无法并发。</p>
</li>
<li>
<p><strong>资源竞争</strong>：占用大量纹理内存或本地内存的内核会降低并发性。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> can_concurrent;<br><span class="hljs-built_in">cudaDeviceGetAttribute</span>(&amp;can_concurrent, cudaDevAttrConcurrentKernels, dev);<br></code></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p><strong>数据传输与内核执行重叠</strong></p>
<ul>
<li>
<p>设备需支持<code>asyncEngineCount &gt; 0</code>。</p>
</li>
<li>
<p><strong>必须使用Page-Locked主机内存</strong></p>
<ol>
<li>
<p><strong>H2D/D2H传输与内核执行重叠</strong>：</p>
<ul>
<li>异步拷贝（<code>cudaMemcpyAsync</code>）与内核并发。</li>
</ul>
</li>
<li>
<p><strong>设备内拷贝（D2D）与内核执行重叠</strong>：</p>
<ul>
<li>
<p>需<code>concurrentKernels</code>支持</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaStream_t stream1, stream2;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream1);<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream2);<br><br><span class="hljs-comment">// 异步H2D传输（流1）</span><br><span class="hljs-built_in">cudaMemcpyAsync</span>(d_data, h_data, size, cudaMemcpyHostToDevice, stream1);<br><br><span class="hljs-comment">// 内核执行（流2，与传输重叠）</span><br>kernel&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, stream2&gt;&gt;&gt;(d_data);<br><br><span class="hljs-comment">// 异步D2H传输（流1）</span><br><span class="hljs-built_in">cudaMemcpyAsync</span>(h_result, d_data, size, cudaMemcpyDeviceToHost, stream1);<br></code></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li>
<p><strong>并发数据传输</strong></p>
<ul>
<li>设备需<code>asyncEngineCount = 2</code>（Compute Capability ≥ 2.0）。</li>
<li><strong>必须使用Page-Locked内存</strong>。</li>
<li>同时进行H2D和D2H传输（双向重叠）</li>
</ul>
</li>
<li>
<p><strong>流管理</strong></p>
<p><strong>流</strong>是命令序列（如内核、内存拷贝），在<strong>同一流内顺序执行</strong>，<strong>不同流间可能并发</strong>，<strong>无显式同步时，流间执行顺序不确定</strong>。</p>
<p>流的创建与销毁</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaStream_t stream;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream);  <span class="hljs-comment">// 创建流</span><br><br><span class="hljs-comment">// 在流中执行操作</span><br>kernel&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, stream&gt;&gt;&gt;(...);<br><span class="hljs-built_in">cudaMemcpyAsync</span>(..., stream);<br><br><span class="hljs-built_in">cudaStreamDestroy</span>(stream);  <span class="hljs-comment">// 销毁流（若流未完成，自动等待后释放资源）</span><br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaStream_t streams[<span class="hljs-number">2</span>];<br><span class="hljs-type">float</span> *h_pinned, *d_data;<br><span class="hljs-built_in">cudaMallocHost</span>(&amp;h_pinned, <span class="hljs-number">2</span> * size);  <span class="hljs-comment">// Page-Locked内存</span><br><span class="hljs-built_in">cudaMalloc</span>(&amp;d_data, <span class="hljs-number">2</span> * size);<br><br><span class="hljs-comment">// 创建流</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++) <br>    <span class="hljs-built_in">cudaStreamCreate</span>(&amp;streams[i]);<br><br><span class="hljs-comment">// 异步操作（流间可能并发）</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++) &#123;<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(d_data + i*size, h_pinned + i*size, <br>                    size, cudaMemcpyHostToDevice, streams[i]);<br>    kernel&lt;&lt;&lt;grid, block, <span class="hljs-number">0</span>, streams[i]&gt;&gt;&gt;(d_data + i*size);<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(h_pinned + i*size, d_data + i*size,<br>                    size, cudaMemcpyDeviceToHost, streams[i]);<br>&#125;<br><br><span class="hljs-comment">// 同步所有流</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++) <br>    <span class="hljs-built_in">cudaStreamSynchronize</span>(streams[i]);<br><br><span class="hljs-comment">// 释放资源</span><br><span class="hljs-built_in">cudaFreeHost</span>(h_pinned);<br><span class="hljs-built_in">cudaFree</span>(d_data);<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; i++) <br>    <span class="hljs-built_in">cudaStreamDestroy</span>(streams[i]);<br></code></pre></td></tr></table></figure>
<p>未指定流或流为<code>0</code>时使用<strong>全局NULL流</strong>（隐式同步所有操作），即默认的编译选项<code>--default-stream legacy</code>，也可以指定–<code>default-stream per-thread</code>或定义宏<code>CUDA_API_PER_THREAD_DEFAULT_STREAM</code>来使每个主机线程都有独立的默认流，支持并发。</p>
<p>流的同步方式有两种：</p>
<ol>
<li>
<p>显式同步</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaStreamSynchronize</span>(stream);  <span class="hljs-comment">// 等待流完成</span><br><span class="hljs-built_in">cudaDeviceSynchronize</span>();        <span class="hljs-comment">// 等待所有流完成</span><br><br><span class="hljs-built_in">cudaStreamWaitEvent</span>();<br><span class="hljs-built_in">cudaStreamQuery</span>(<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>隐式同步</p>
<p>NULL流中的操作会同步所有其他流。</p>
</li>
</ol>
</li>
</ol>
<p>当主机线程在两个流的命令之间插入以下操作时，<strong>不同流的命令将失去并发性</strong>，导致串行执行:</p>
<ol>
<li>
<p><strong>页锁定主机内存分配</strong></p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">cudaMallocHost</span>(&amp;ptr, size);  <span class="hljs-comment">// 阻塞所有流的并发</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>设备内存分配</strong></p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">cudaMalloc</span>(&amp;d_ptr, size);    <span class="hljs-comment">// 强制同步</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>设备内存初始化（如cudaMemset）</strong></p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">cudaMemset</span>(d_ptr, <span class="hljs-number">0</span>, size);  <span class="hljs-comment">// 隐式同步点</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>同一设备内存的拷贝（D2D）</strong></p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">cudaMemcpy</span>(dst, src, size, cudaMemcpyDeviceToDevice); <span class="hljs-comment">// 内部同步</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>NULL流（默认流）中的任何操作</strong></p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss">kernel&lt;&lt;&lt;<span class="hljs-attribute">grid</span>, block&gt;&gt;&gt;();  <span class="hljs-comment">// 默认流操作会同步所有流</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>L1/Shared内存配置切换</strong>
（针对Compute Capability 3.x/7.x设备）</p>
</li>
</ol>
<p>两个流之间的执行重叠量取决于向每个流发出命令的顺序，以及设备是否支持数据传输和内核执行的重叠，并发内核执行，或并发数据传输。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><strong>场景</strong></th>
<th style="text-align:left"><strong>问题根源</strong></th>
<th style="text-align:left"><strong>优化方法</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">不支持并发数据传输的设备</td>
<td style="text-align:left">H2D/D2H共用引擎</td>
<td style="text-align:left">无解，需升级硬件</td>
</tr>
<tr>
<td style="text-align:left">支持并发数据传输的设备</td>
<td style="text-align:left">任务提交顺序限制重叠</td>
<td style="text-align:left">分组提交（H2D→Kernel→D2H）</td>
</tr>
<tr>
<td style="text-align:left">计算能力≤3.0的设备</td>
<td style="text-align:left">内核启动依赖全局线程块进度</td>
<td style="text-align:left">提前提交所有内核，延迟D2H</td>
</tr>
<tr>
<td style="text-align:left">任何设备</td>
<td style="text-align:left">NULL流或隐式同步操作</td>
<td style="text-align:left">使用显式流，避免全局操作</td>
</tr>
</tbody>
</table>
<p>例如，我们在不支持并发数据传输的设备上，执行下面的逻辑：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 流0：H2D -&gt; Kernel -&gt; D2H</span><br><span class="hljs-comment">// 流1：H2D -&gt; Kernel -&gt; D2H （提交顺序导致串行化）</span><br></code></pre></td></tr></table></figure>
<p>流1的H2D必须等待流0的D2H完成（因为D2H和H2D共用传输引擎）,由于<strong>零重叠</strong>，所以流0和流1是完全串行执行。</p>
<p><strong><code>cudaLaunchHostFunc</code></strong> 函数在CUDA流的特定位置插入一个<strong>主机端函数</strong>，该函数会在流中<strong>此前所有命令完成</strong>后自动触发，由CUDA runtime调度，不会阻塞</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaLaunchHostFunc</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    cudaStream_t stream,          <span class="hljs-comment">// 目标流</span></span></span><br><span class="hljs-params"><span class="hljs-function">    cudaHostFn_t fn,              <span class="hljs-comment">// 回调函数指针</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">void</span>* userData                <span class="hljs-comment">// 传递给回调的用户数据</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function"><span class="hljs-type">void</span> CUDART_CB <span class="hljs-title">MyCallback</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    cudaStream_t stream,  <span class="hljs-comment">// 关联的流</span></span></span><br><span class="hljs-params"><span class="hljs-function">    cudaError_t status,   <span class="hljs-comment">// 流中前置操作的状态（成功/错误）</span></span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">void</span>* data            <span class="hljs-comment">// 用户数据</span></span></span><br><span class="hljs-params"><span class="hljs-function">)</span></span>;<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">cudaMemcpyAsync</span>(..., stream);  <span class="hljs-comment">// 操作1</span><br>kernel&lt;&lt;&lt;..., stream&gt;&gt;&gt;();     <span class="hljs-comment">// 操作2</span><br><span class="hljs-built_in">cudaLaunchHostFunc</span>(stream, MyCallback, data); <span class="hljs-comment">// 回调</span><br><span class="hljs-comment">// MyCallback 仅在操作1和2完成后执行</span><br></code></pre></td></tr></table></figure>
<p>需要注意的是回调函数调用CUDA API（如<code>cudaMemcpy</code>），可能等待自身完成，导致死锁。</p>
<p>在运行时，高优先级流中的待处理工作优先于低优先级流中的待处理工作</p>
<p>可以使用<code>cudaDeviceGetStreamPriorityRange()</code>获取当前的优先级范围，并且利用<code>cudaStreamCreateWithPriority()</code>设定流的优先级。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// get the range of stream priorities for this device</span><br><span class="hljs-type">int</span> priority_high, priority_low;<br><span class="hljs-built_in">cudaDeviceGetStreamPriorityRange</span>(&amp;priority_low, &amp;priority_high);<br><span class="hljs-comment">// create streams with highest and lowest available priorities</span><br>cudaStream_t st_high, st_low;<br><span class="hljs-built_in">cudaStreamCreateWithPriority</span>(&amp;st_high, cudaStreamNonBlocking, priority_high);<br><span class="hljs-built_in">cudaStreamCreateWithPriority</span>(&amp;st_low, cudaStreamNonBlocking, priority_low);<br></code></pre></td></tr></table></figure>
<h3 id="Graphs">Graphs</h3>
<p>传统流模型每次内核启动或内存拷贝都需要CPU驱动执行设置工作（如参数验证、GPU命令生成），对于短时内核，开销占比显著，而且无法让CUDA看到完整任务流，难以全局优化。</p>
<p>对此Graphs将整个工作流（包括操作和依赖）预先定义为<strong>图结构</strong>，后续可重复执行，也方便了实例化阶段完成大部分初始化，减少运行时开销。</p>
<p>以下是创建一个图的简单流程：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// Create the graph - it starts out empty</span><br><span class="hljs-built_in">cudaGraphCreate</span>(&amp;graph, <span class="hljs-number">0</span>);<br><span class="hljs-comment">// For the purpose of this example, we&#x27;ll create</span><br><span class="hljs-comment">// the nodes separately from the dependencies to</span><br><span class="hljs-comment">// demonstrate that it can be done in two stages.</span><br><span class="hljs-comment">// Note that dependencies can also be specified</span><br><span class="hljs-comment">// at node creation.</span><br><span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;a, graph, <span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;nodeParams);<br><span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;b, graph, <span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;nodeParams);<br><span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;c, graph, <span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;nodeParams);<br><span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;d, graph, <span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;nodeParams);<br><span class="hljs-comment">// Now set up dependencies on each node</span><br><span class="hljs-built_in">cudaGraphAddDependencies</span>(graph, &amp;a, &amp;b, <span class="hljs-number">1</span>); <span class="hljs-comment">// A-&gt;B</span><br><span class="hljs-built_in">cudaGraphAddDependencies</span>(graph, &amp;a, &amp;c, <span class="hljs-number">1</span>); <span class="hljs-comment">// A-&gt;C</span><br><span class="hljs-built_in">cudaGraphAddDependencies</span>(graph, &amp;b, &amp;d, <span class="hljs-number">1</span>); <span class="hljs-comment">// B-&gt;D</span><br><span class="hljs-built_in">cudaGraphAddDependencies</span>(graph, &amp;c, &amp;d, <span class="hljs-number">1</span>); <span class="hljs-comment">// C-&gt;D</span><br></code></pre></td></tr></table></figure>
<p><img src="Graph.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="Graph" /></p>
<p>也可以同步捕获流来创建一个图：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaGraph_t graph;<br><br><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream); <span class="hljs-comment">// 进入捕获模式,后续放入流的操作不会立即执行，而是被记录到内部图中</span><br>kernel_A&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...); <span class="hljs-comment">//被捕获为图节点</span><br>kernel_B&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...);<br><span class="hljs-built_in">libraryCall</span>(stream); <span class="hljs-comment">//// 库函数调用（需支持捕获）</span><br>kernel_C&lt;&lt;&lt; ..., stream &gt;&gt;&gt;(...);<br><span class="hljs-built_in">cudaStreamEndCapture</span>(stream, &amp;graph); <span class="hljs-comment">//// 返回构建的图graph</span><br></code></pre></td></tr></table></figure>
<p>支持普通流和每线程流（<code>cudaStreamPerThread</code>），<strong>不支持</strong>传统NULL流（<code>cudaStreamLegacy</code>），可以通过下述代码查询：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">cudaStreamIsCapturing</span>(stream, &amp;isCapturing);  <span class="hljs-comment">// 检查流是否处于捕获模式</span><br></code></pre></td></tr></table></figure>
<p>上图的依赖关系，我们可以通过引入事件来实现跨流的依赖：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// stream1 is the origin stream</span><br><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream1);<br>kernel_A&lt;&lt;&lt; ..., stream1 &gt;&gt;&gt;(...);<br><span class="hljs-comment">// Fork into stream2</span><br><span class="hljs-built_in">cudaEventRecord</span>(event1, stream1);<br><span class="hljs-built_in">cudaStreamWaitEvent</span>(stream2, event1);<br>kernel_B&lt;&lt;&lt; ..., stream1 &gt;&gt;&gt;(...);<br>kernel_C&lt;&lt;&lt; ..., stream2 &gt;&gt;&gt;(...);<br><span class="hljs-comment">// Join stream2 back to origin stream (stream1)</span><br><span class="hljs-built_in">cudaEventRecord</span>(event2, stream2);<br><span class="hljs-built_in">cudaStreamWaitEvent</span>(stream1, event2);<br>kernel_D&lt;&lt;&lt; ..., stream1 &gt;&gt;&gt;(...);<br><span class="hljs-comment">// End capture in the origin stream</span><br><span class="hljs-built_in">cudaStreamEndCapture</span>(stream1, &amp;graph);<br><span class="hljs-comment">// stream1 and stream2 no longer in capture mode</span><br></code></pre></td></tr></table></figure>
<p>可以这样理解上述的代码：首先创建了stream1这条流，从kernel_A 触发，生成对的event1事件，创建第二条流等待event1事件，也就是kernel_A的创建完成，那么stream2也自然建立了和kernel_A的关系，kernel_B延续stream1，kernel_C延续stream2, 之后建立第二个事件 也就是stream2（kernel_C的是否完成），同时stream1流等待event2，当stream1流和stream2流都通过时，也就是kernel_B和kernel_C都完成时，kernel_C延续stream1，从而实现了图示的效果。</p>
<p>注意下面的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// stream1 is the origin stream</span><br><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream1);<br>kernel_A&lt;&lt;&lt; ..., stream1 &gt;&gt;&gt;(...);<br><br><span class="hljs-comment">// Fork into stream2</span><br><span class="hljs-built_in">cudaEventRecord</span>(event1, stream1);<br><span class="hljs-built_in">cudaStreamWaitEvent</span>(stream2, event1);<br>kernel_B&lt;&lt;&lt; ..., stream1 &gt;&gt;&gt;(...);<br>kernel_C&lt;&lt;&lt; ..., stream2 &gt;&gt;&gt;(...);<br><br><span class="hljs-comment">// 错误依赖关系</span><br><span class="hljs-built_in">cudaEventRecord</span>(event2, stream1);<br><span class="hljs-built_in">cudaStreamWaitEvent</span>(stream2, event2);<br><br><span class="hljs-comment">//这里编程stream2 无影响</span><br>kernel_D&lt;&lt;&lt; ..., stream2 &gt;&gt;&gt;(...);<br><br><span class="hljs-comment">// End capture in the origin stream</span><br><span class="hljs-built_in">cudaStreamEndCapture</span>(stream1, &amp;graph);<br><span class="hljs-comment">// stream1 and stream2 no longer in capture mode</span><br></code></pre></td></tr></table></figure>
<p>由于先创建了stream1，所以stream1最大可能最先执行完，所以stream1需要等待stream2的完成，而不是stream2等待stream1，而最后的kernel_D无论基于哪个流，二者都已经同步完成，所以不影响。</p>
<p>需要注意的是：<code>cudaStreamBeginCapture</code>哪个流开始，<code>cudaStreamEndCapture</code>必须结束对应的流。</p>
<p>捕获模式下的流和事件仅是<strong>图构建的临时抽象</strong>，不代表实际GPU任务队列。尝试同步/查询会导致：</p>
<ul>
<li>逻辑矛盾（无法查询未提交执行的任务状态）</li>
<li>潜在死锁（捕获未完成却要求同步）</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream);<br>kernel&lt;&lt;&lt;..., stream&gt;&gt;&gt;();<br><span class="hljs-built_in">cudaStreamSynchronize</span>(stream); <span class="hljs-comment">// 错误！流在捕获模式</span><br></code></pre></td></tr></table></figure>
<p>跨图合并也是禁止的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 图1</span><br><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream1);<br><span class="hljs-built_in">cudaEventRecord</span>(event1, stream1);<br><span class="hljs-built_in">cudaStreamEndCapture</span>(stream1, &amp;graph1);<br><br><span class="hljs-comment">// 图2（错误尝试合并）</span><br><span class="hljs-built_in">cudaStreamBeginCapture</span>(stream2);<br><span class="hljs-built_in">cudaStreamWaitEvent</span>(stream2, event1); <span class="hljs-comment">// 错误！event1属于不同图</span><br></code></pre></td></tr></table></figure>
<p>可以按照如下流程处理失效的情况：</p>
<p><img src="%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="处理流程" /></p>
<p>最后需要注意的是，图定义对象（<code>cudaGraph_t</code>）不能被多线程同时访问（包括创建/修改/销毁）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaGraph_t graph;<br><br><span class="hljs-comment">// 线程1</span><br><span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;node1, graph, ...);<br><br><span class="hljs-comment">// 线程2（同时操作同一graph）</span><br><span class="hljs-built_in">cudaGraphAddMemcpyNode</span>(&amp;node2, graph, ...); <span class="hljs-comment">// 危险！</span><br></code></pre></td></tr></table></figure>
<p>这时候需要使用线程互斥锁保护图对象操作：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++">std::mutex graph_mutex;<br>&#123;<br>    <span class="hljs-function">std::lock_guard&lt;std::mutex&gt; <span class="hljs-title">lock</span><span class="hljs-params">(graph_mutex)</span></span>;<br>    <span class="hljs-built_in">cudaGraphAddKernelNode</span>(&amp;node, graph, ...);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>可执行图实例（<code>cudaGraphExec_t</code>）不能并发执行同一实例,连续启动同一可执行图时，CUDA保证</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">Launch <span class="hljs-number">1</span> → Launch <span class="hljs-number">2</span> → Launch <span class="hljs-number">3</span> （严格顺序）<br></code></pre></td></tr></table></figure>
<p>即使使用不同流，也无法实现同一图实例的并行执行：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaGraphLaunch</span>(execGraph, stream1);  <span class="hljs-comment">// 第一次启动</span><br><span class="hljs-built_in">cudaGraphLaunch</span>(execGraph, stream2);  <span class="hljs-comment">// 阻塞直到第一次完成</span><br></code></pre></td></tr></table></figure>
<p>可以采用如下的方式实现多线程共享图：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 主线程构建图</span><br>cudaGraph_t graph;<br><span class="hljs-built_in">buildGraph</span>(&amp;graph);<br><br><span class="hljs-comment">// 子线程使用（只读）</span><br>cudaGraphExec_t localExec;<br><span class="hljs-built_in">cudaGraphInstantiate</span>(&amp;localExec, graph, ...); <span class="hljs-comment">// 每个线程独立实例化</span><br><span class="hljs-built_in">cudaGraphLaunch</span>(localExec, localStream);<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaGraphExec_t execGraph1, execGraph2;<br><span class="hljs-built_in">cudaGraphInstantiate</span>(&amp;execGraph1, graph, ...);<br><span class="hljs-built_in">cudaGraphInstantiate</span>(&amp;execGraph2, graph, ...); <span class="hljs-comment">// 创建副本</span><br><br><span class="hljs-comment">// 真正并行执行</span><br><span class="hljs-built_in">cudaGraphLaunch</span>(execGraph1, stream1);<br><span class="hljs-built_in">cudaGraphLaunch</span>(execGraph2, stream2);<br></code></pre></td></tr></table></figure>
<p>CUDA 事件(Event)是 CUDA 编程中用于监控设备执行进度和精确计时的机制。它们允许应用程序在程序中的任意点异步记录事件，并查询这些事件的完成状态。</p>
<ul>
<li>事件完成意味着所有在该事件之前提交的任务（或指定流中的所有命令）已完成</li>
<li>流0(默认流)中的事件在所有流中所有前置任务和命令完成后才标记为完成</li>
<li>主要用于：计时操作、同步点、性能分析</li>
</ul>
<p><code>cudaEventCreate</code> 函数创建一个新的事件对象，可以通过 <code>cudaEvent_t</code> 类型的变量引用:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaEvent_t start, stop;<br><span class="hljs-built_in">cudaEventCreate</span>(&amp;start);<br><span class="hljs-built_in">cudaEventCreate</span>(&amp;stop);<br></code></pre></td></tr></table></figure>
<p>当不再需要事件时，应该销毁它以释放相关资源:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaEventDestroy</span>(start);<br><span class="hljs-built_in">cudaEventDestroy</span>(stop);<br></code></pre></td></tr></table></figure>
<p>事件最常用的场景是测量代码段的执行时间，特别是异步操作的执行时间:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 记录开始事件</span><br><span class="hljs-built_in">cudaEventRecord</span>(start, <span class="hljs-number">0</span>);  <span class="hljs-comment">// 0表示默认流</span><br><br><span class="hljs-comment">// 执行要计时的代码</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span>; ++i) &#123;<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(inputDev + i * size, inputHost + i * size,<br>                   size, cudaMemcpyHostToDevice, stream[i]);<br>    MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">512</span>, <span class="hljs-number">0</span>, stream[i]&gt;&gt;&gt;<br>              (outputDev + i * size, inputDev + i * size, size);<br>    <span class="hljs-built_in">cudaMemcpyAsync</span>(outputHost + i * size, outputDev + i * size,<br>                   size, cudaMemcpyDeviceToHost, stream[i]);<br>&#125;<br><br><span class="hljs-comment">// 记录结束事件</span><br><span class="hljs-built_in">cudaEventRecord</span>(stop, <span class="hljs-number">0</span>);<br><br><span class="hljs-comment">// 等待事件完成</span><br><span class="hljs-built_in">cudaEventSynchronize</span>(stop);<br><br><span class="hljs-comment">// 计算时间差</span><br><span class="hljs-type">float</span> elapsedTime;<br><span class="hljs-built_in">cudaEventElapsedTime</span>(&amp;elapsedTime, start, stop);<br></code></pre></td></tr></table></figure>
<h3 id="Multi-Device-System（多设备系统）">Multi-Device System（多设备系统）</h3>
<p>在具有多个GPU的系统中，CUDA提供了设备枚举功能来识别和查询可用设备：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">int</span> deviceCount;<br><span class="hljs-built_in">cudaGetDeviceCount</span>(&amp;deviceCount);  <span class="hljs-comment">// 获取系统中CUDA设备数量</span><br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> device = <span class="hljs-number">0</span>; device &lt; deviceCount; ++device) &#123;<br>    cudaDeviceProp deviceProp;<br>    <span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;deviceProp, device);  <span class="hljs-comment">// 获取设备属性</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Device %d: %s\n&quot;</span>, device, deviceProp.name);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;  Compute Capability: %d.%d\n&quot;</span>, <br>           deviceProp.major, deviceProp.minor);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;  Total Global Memory: %.2f GB\n&quot;</span>, <br>           deviceProp.totalGlobalMem/<span class="hljs-number">1024.0</span>/<span class="hljs-number">1024.0</span>/<span class="hljs-number">1024.0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>每个主机线程有&quot;当前设备&quot;的概念，内存分配和内核启动都在当前设备上执行，默认当前设备是设备0：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//使用cudaSetDevice切换设备</span><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>);  <span class="hljs-comment">// 切换到设备0</span><br><span class="hljs-type">float</span>* d_data0;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;d_data0, size);  <span class="hljs-comment">// 在设备0上分配内存</span><br><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">1</span>);  <span class="hljs-comment">// 切换到设备1</span><br><span class="hljs-type">float</span>* d_data1;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;d_data1, size);  <span class="hljs-comment">// 在设备1上分配内存</span><br></code></pre></td></tr></table></figure>
<p>涉及到对于流的处理时，如果内核启动是向未与当前设备关联的流发出的，则内核启动将失败：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>); <span class="hljs-comment">// Set device 0 as current</span><br>cudaStream_t s0;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;s0); <span class="hljs-comment">// Create stream s0 on device 0</span><br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">64</span>, <span class="hljs-number">0</span>, s0&gt;&gt;&gt;(); <span class="hljs-comment">// Launch kernel on device 0 in s0</span><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">1</span>); <span class="hljs-comment">// Set device 1 as current</span><br>cudaStream_t s1;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;s1); <span class="hljs-comment">// Create stream s1 on device 1</span><br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">64</span>, <span class="hljs-number">0</span>, s1&gt;&gt;&gt;(); <span class="hljs-comment">// Launch kernel on device 1 in s1</span><br><span class="hljs-comment">// This kernel launch will fail:</span><br>MyKernel&lt;&lt;&lt;<span class="hljs-number">100</span>, <span class="hljs-number">64</span>, <span class="hljs-number">0</span>, s0&gt;&gt;&gt;(); <span class="hljs-comment">// Launch kernel on device 1 in s0</span><br></code></pre></td></tr></table></figure>
<p>对于跨设备操作，遵循以下的规则：</p>
<table>
<thead>
<tr>
<th style="text-align:left">操作</th>
<th style="text-align:left">跨设备行为</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">cudaEventRecord</td>
<td style="text-align:left">事件和流必须在同一设备</td>
</tr>
<tr>
<td style="text-align:left">cudaEventElapsedTime</td>
<td style="text-align:left">两个事件必须在同一设备</td>
</tr>
<tr>
<td style="text-align:left">cudaEventSynchronize/Query</td>
<td style="text-align:left">支持跨设备操作</td>
</tr>
<tr>
<td style="text-align:left">cudaStreamWaitEvent</td>
<td style="text-align:left">支持跨设备同步</td>
</tr>
</tbody>
</table>
<p>对于支持PCIe拓扑或NVLink连接的设备之间可以进行点对点访问：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-type">int</span> canAccessPeer;<br><span class="hljs-built_in">cudaDeviceCanAccessPeer</span>(&amp;canAccessPeer, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>);  <span class="hljs-comment">// 检查设备0能否访问设备1</span><br><br><span class="hljs-keyword">if</span> (canAccessPeer) &#123;<br>    <span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>);<br>    <span class="hljs-built_in">cudaDeviceEnablePeerAccess</span>(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>);  <span class="hljs-comment">// 设备0启用对设备1的访问</span><br>    <br>    <span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">1</span>);<br>    <span class="hljs-built_in">cudaDeviceEnablePeerAccess</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);  <span class="hljs-comment">// 设备1启用对设备0的访问</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>P2P内存访问可直接访问对等设备内存，避免通过主机内存中转，使得指针在不同设备间保持有效性。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 设备0上分配内存</span><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>);<br><span class="hljs-type">float</span>* p0;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;p0, size);<br><br><span class="hljs-comment">// 设备1上直接使用设备0的内存</span><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">1</span>);<br>MyKernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(p0);  <span class="hljs-comment">// 直接访问设备0的内存</span><br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 传统方法(通过主机中转)</span><br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">0</span>);<br><span class="hljs-built_in">cudaMemcpy</span>(hostPtr, dev0Ptr, size, cudaMemcpyDeviceToHost);<br><span class="hljs-built_in">cudaSetDevice</span>(<span class="hljs-number">1</span>);<br><span class="hljs-built_in">cudaMemcpy</span>(dev1Ptr, hostPtr, size, cudaMemcpyHostToDevice);<br><br><span class="hljs-comment">// P2P直接拷贝</span><br><span class="hljs-built_in">cudaMemcpyPeer</span>(dev1Ptr, <span class="hljs-number">1</span>, dev0Ptr, <span class="hljs-number">0</span>, size);  <span class="hljs-comment">// 设备0到设备1的直接拷贝</span><br></code></pre></td></tr></table></figure>
<p>异步拷贝方式如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMemcpyPeerAsync</span>(dest, destDevice, src, srcDevice, size, stream);<br></code></pre></td></tr></table></figure>
<p>在Linux系统上应禁用IOMMU以获得最佳P2P性能，IOMMU（Input-Output Memory Management Unit）是一种硬件功能，它类似于CPU中的MMU（内存管理单元），但专门为I/O设备设计，用于管理设备对系统内存的访问。</p>
<table>
<thead>
<tr>
<th style="text-align:left">特性</th>
<th style="text-align:left">MMU</th>
<th style="text-align:left">IOMMU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">服务对象</td>
<td style="text-align:left">CPU</td>
<td style="text-align:left">I/O设备</td>
</tr>
<tr>
<td style="text-align:left">主要功能</td>
<td style="text-align:left">虚拟地址→物理地址转换</td>
<td style="text-align:left">设备地址→物理地址转换</td>
</tr>
<tr>
<td style="text-align:left">保护目标</td>
<td style="text-align:left">进程间内存隔离</td>
<td style="text-align:left">设备间内存隔离</td>
</tr>
</tbody>
</table>
</li>
</ol>
<p>统一地址空间是CUDA架构中一项重要特性，它从根本上简化了多设备系统中的内存管理，在64位进程中，CUDA创建一个跨越<strong>主机内存</strong>和<strong>所有计算能力2.0+设备内存</strong>的单一虚拟地址空间：</p>
<ul>
<li>每个内存地址在系统中具有唯一性</li>
<li>指针值本身包含位置信息（主机/设备）</li>
<li>地址范围：通常为40位或48位虚拟地址空间（取决于GPU架构）</li>
</ul>
<p>利用GPU同一地址空间可以实现：</p>
<p>**指针属性的查询：**通过<code>cudaPointerGetAttributes()</code>可确定指针的实际位置</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaPointerAttributes attributes;<br><span class="hljs-built_in">cudaPointerGetAttributes</span>(&amp;attributes, ptr);<br><br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Memory type: %s\n&quot;</span>, <br>       attributes.type == cudaMemoryTypeHost ? <span class="hljs-string">&quot;Host&quot;</span> :<br>       attributes.type == cudaMemoryTypeDevice ? <span class="hljs-string">&quot;Device&quot;</span> : <span class="hljs-string">&quot;Managed&quot;</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Device ID: %d\n&quot;</span>, attributes.device);<br></code></pre></td></tr></table></figure>
<p>**智能内存的拷贝：**使用<code>cudaMemcpyDefault</code>自动判断拷贝方</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 自动识别src和dst位置（主机↔设备/设备↔设备）</span><br><span class="hljs-built_in">cudaMemcpy</span>(dst, src, size, cudaMemcpyDefault);<br></code></pre></td></tr></table></figure>
<p>便携式内存分配<code>cudaHostAlloc</code>分配的内存自动支持</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span> *h_data;<br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;h_data, size, cudaHostAllocDefault);<br><br><span class="hljs-comment">// 所有支持统一地址空间的设备均可直接访问</span><br>MyKernel&lt;&lt;&lt;...&gt;&gt;&gt;(h_data);  <span class="hljs-comment">// 无需获取设备指针</span><br></code></pre></td></tr></table></figure>
<p>和Linux的进程间通信一样，CUDA IPC（Inter-Process Communication）是一组允许不同进程间共享GPU内存和事件的高级功能，对于同一进程的所有线程天然共享设备指针和事件句柄，不同进程的地址空间相互独立，需显式IPC机制。</p>
<p>需要注意的是，<code>cudaMallocManaged</code>分配的内存不支持IPC，通信进程必须使用相同版本的CUDA驱动和运行时。</p>
<p>可以通过<strong>内存共享</strong>和事件共享来实现IPC通信：</p>
<p>对于<strong>内存共享</strong>，在GPU页表中建立跨进程映射，使用唯一的IPC句柄替代裸指针，同时采用引用计数，防止过早释放共享内存。</p>
<p>发送方进程执行：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">float</span>* d_data;<br><span class="hljs-built_in">cudaMalloc</span>(&amp;d_data, size);  <span class="hljs-comment">// 分配设备内存</span><br><br>cudaIpcMemHandle_t handle;<br><span class="hljs-built_in">cudaIpcGetMemHandle</span>(&amp;handle, d_data);  <span class="hljs-comment">// 获取IPC句柄</span><br><br><span class="hljs-comment">// 通过OS机制传递handle（如共享内存、管道、文件等）</span><br><span class="hljs-built_in">write_to_ipc_channel</span>(&amp;handle, <span class="hljs-built_in">sizeof</span>(handle));<br></code></pre></td></tr></table></figure>
<p>接收方进程执行：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaIpcMemHandle_t handle;<br><span class="hljs-built_in">read_from_ipc_channel</span>(&amp;handle, <span class="hljs-built_in">sizeof</span>(handle));  <span class="hljs-comment">// 获取句柄</span><br><br><span class="hljs-type">float</span>* foreign_d_data;<br><span class="hljs-built_in">cudaIpcOpenMemHandle</span>(&amp;foreign_d_data, handle, <br>                    cudaIpcMemLazyEnablePeerAccess);  <span class="hljs-comment">// 打开句柄</span><br><br><span class="hljs-comment">// 现在foreign_d_data可当作本地设备指针使用</span><br></code></pre></td></tr></table></figure>
<p>可以指定Handle的打开模式：</p>
<table>
<thead>
<tr>
<th style="text-align:left">模式标志</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>cudaIpcMemLazyEnablePeerAccess</code></td>
<td style="text-align:left">按需自动建立P2P访问</td>
</tr>
<tr>
<td style="text-align:left"><code>cudaIpcMemLazyDisablePeerAccess</code></td>
<td style="text-align:left">禁用P2P访问</td>
</tr>
</tbody>
</table>
<p>对于<strong>事件共享</strong>，在设备层面创建跨进程可见对象，通过GPU硬件信号实现跨进程同步。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 进程A创建事件并共享</span><br>cudaEvent_t event;<br><span class="hljs-built_in">cudaEventCreate</span>(&amp;event, cudaEventInterprocess);<br>cudaIpcEventHandle_t event_handle;<br><span class="hljs-built_in">cudaIpcGetEventHandle</span>(&amp;event_handle, event);<br><br><span class="hljs-comment">// 进程B打开事件</span><br>cudaEvent_t foreign_event;<br><span class="hljs-built_in">cudaIpcOpenEventHandle</span>(&amp;foreign_event, event_handle);<br></code></pre></td></tr></table></figure>
<p>必须使用<code>cudaEventInterprocess</code>标志创建事件，此时的共享事件只能用于同步，而不能用于计时。</p>
<h3 id="CUDA-Error-Checking">CUDA Error Checking</h3>
<p>所有CUDA Runtime函数运行失败都会返回错误码，对于异步函数，因为该函数在设备完成任务之前返回，错误代码仅仅报告在运行任务之前host上发生的错误，不可能报告device上任何异步错误，需要后续进行同步操作检测。</p>
<p>对于同步函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaError_t err = <span class="hljs-built_in">cudaMemcpy</span>(dst, src, size, cudaMemcpyHostToDevice);<br><span class="hljs-comment">// 错误立即可知，包含设备执行错误</span><br></code></pre></td></tr></table></figure>
<p>对于异步函数：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">MyKernel&lt;&lt;&lt;...&gt;&gt;&gt;(); <span class="hljs-comment">// 启动不返回错误</span><br><span class="hljs-comment">// 仅后续同步才能发现内核执行错误</span><br></code></pre></td></tr></table></figure>
<p>CUDA Errorshiyong如下API进行检测：</p>
<table>
<thead>
<tr>
<th style="text-align:left">函数</th>
<th style="text-align:left">返回值</th>
<th style="text-align:left">副作用</th>
<th style="text-align:left">适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>cudaPeekAtLastError()</code></td>
<td style="text-align:left">当前错误码</td>
<td style="text-align:left">无</td>
<td style="text-align:left">检查错误但不破坏错误上下文</td>
</tr>
<tr>
<td style="text-align:left"><code>cudaGetLastError()</code></td>
<td style="text-align:left">当前错误码</td>
<td style="text-align:left">重置为cudaSuccess</td>
<td style="text-align:left">标准错误处理流程</td>
</tr>
</tbody>
</table>
<p>对于标准的内核错误，参照如下方式进行：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 清除之前可能存在的错误</span><br><span class="hljs-built_in">cudaGetLastError</span>();<br><br><span class="hljs-comment">// 启动内核</span><br>MyKernel&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(...);<br><br><span class="hljs-comment">// 检查启动参数错误</span><br>cudaError_t launchErr = <span class="hljs-built_in">cudaPeekAtLastError</span>();<br><span class="hljs-keyword">if</span> (launchErr != cudaSuccess) &#123;<br>    <span class="hljs-built_in">handleLaunchError</span>(launchErr);<br>&#125;<br><br><span class="hljs-comment">// 同步并检查执行错误</span><br>cudaError_t syncErr = <span class="hljs-built_in">cudaDeviceSynchronize</span>();<br><span class="hljs-keyword">if</span> (syncErr != cudaSuccess) &#123;<br>    <span class="hljs-built_in">handleRuntimeError</span>(syncErr);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>对于流式错误检测：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs C++">cudaStream_t stream;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream);<br><br><span class="hljs-comment">// 启动多个异步操作</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; ++i) &#123;<br>    <span class="hljs-built_in">cudaGetLastError</span>(); <span class="hljs-comment">// 清除错误状态</span><br>    Kernel&lt;&lt;&lt;..., stream&gt;&gt;&gt;(...);<br>    cudaError_t err = <span class="hljs-built_in">cudaStreamQuery</span>(stream);<br>    <span class="hljs-keyword">if</span> (err == cudaErrorNotReady) &#123;<br>        <span class="hljs-comment">// 正常情况，操作未完成</span><br>    &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (err != cudaSuccess) &#123;<br>        <span class="hljs-comment">// 真实错误处理</span><br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 最终错误检查</span><br>cudaError_t finalErr = <span class="hljs-built_in">cudaStreamSynchronize</span>(stream);<br></code></pre></td></tr></table></figure>
<p>如何处理错误，在CUDA 8+中定义了错误回调的机制：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">void</span> __host__ <span class="hljs-title">errorCallback</span><span class="hljs-params">(cudaStream_t stream, cudaError_t status, <span class="hljs-type">void</span>* userData)</span> </span>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Async error detected: %s\n&quot;</span>, <span class="hljs-built_in">cudaGetErrorString</span>(status));<br>&#125;<br><br><span class="hljs-comment">// 注册回调</span><br><span class="hljs-built_in">cudaStreamAddCallback</span>(stream, errorCallback, <span class="hljs-literal">nullptr</span>, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure>
<h3 id="Texture-and-Surface-Memory">Texture and Surface Memory</h3>
<p>纹理内存（texture memory）和表面内存（surface memory）类似于常量内存，是有缓存的全局变量，可见范围和生命周期一样，一般仅可读（表面内存可写），但内存容量更大。</p>
<h4 id="Texture-Memory">Texture Memory</h4>
<p>在旧式纹理API中使用如下方式静态引用纹理：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 声明纹理引用（必须在文件作用域）</span><br>texture&lt;<span class="hljs-type">float</span>, <span class="hljs-number">2</span>, cudaReadModeElementType&gt; texRef;<br><br><span class="hljs-comment">// 运行时绑定</span><br>cudaChannelFormatDesc desc = <span class="hljs-built_in">cudaCreateChannelDesc</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-built_in">cudaBindTexture2D</span>(<span class="hljs-number">0</span>, texRef, devPtr, desc, width, height, pitch);<br><br><span class="hljs-comment">// 内核中使用</span><br><span class="hljs-type">float</span> val = <span class="hljs-built_in">tex2D</span>(texRef, x, y);<br></code></pre></td></tr></table></figure>
<p>CUDA3.0+可以在运行时动态创建纹理：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaTextureDesc</span><br>&#123;<br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureAddressMode</span> addressMode[<span class="hljs-number">3</span>];<br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureFilterMode</span> filterMode;<br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureReadMode</span> readMode;<br>    <span class="hljs-type">int</span> sRGB;<br>    <span class="hljs-type">int</span> normalizedCoords;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> maxAnisotropy;<br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureFilterMode</span> mipmapFilterMode;<br>    <span class="hljs-type">float</span> mipmapLevelBias;<br>    <span class="hljs-type">float</span> minMipmapLevelClamp;<br>    <span class="hljs-type">float</span> maxMipmapLevelClamp;<br>&#125;;<br><br><br><br><span class="hljs-comment">// 创建纹理对象</span><br>cudaResourceDesc resDesc;<br><span class="hljs-built_in">memset</span>(&amp;resDesc, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(resDesc));<br>resDesc.resType = cudaResourceTypeLinear;<br>resDesc.res.linear.devPtr = devPtr;<br>resDesc.res.linear.desc = <span class="hljs-built_in">cudaCreateChannelDesc</span>&lt;<span class="hljs-type">float</span>&gt;();<br>resDesc.res.linear.sizeInBytes = width * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>cudaTextureDesc texDesc;<br><span class="hljs-built_in">memset</span>(&amp;texDesc, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(texDesc));<br>texDesc.addressMode[<span class="hljs-number">0</span>] = cudaAddressModeClamp;<br>texDesc.filterMode = cudaFilterModeLinear;<br>texDesc.readMode = cudaReadModeElementType;<br><br>cudaTextureObject_t texObj;<br><span class="hljs-built_in">cudaCreateTextureObject</span>(&amp;texObj, &amp;resDesc, &amp;texDesc, <span class="hljs-literal">NULL</span>);<br><br><span class="hljs-comment">// 内核中使用</span><br><span class="hljs-type">float</span> val = <span class="hljs-built_in">tex1Dfetch</span>&lt;<span class="hljs-type">float</span>&gt;(texObj, x);<br></code></pre></td></tr></table></figure>
<p>下面一段代码展示了利用纹理对象实现图像旋转的操作：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cuda_runtime.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;device_launch_parameters.h&quot;</span></span><br><br><span class="hljs-comment">// rotate kernel</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transformKernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, cudaTextureObject_t textObj, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height, <span class="hljs-type">float</span> theta)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">//归一化 纹理采样前的标准预处理步骤</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br><br>    <span class="hljs-type">float</span> u = x / (<span class="hljs-type">float</span>)width;<br>    <span class="hljs-type">float</span> v = y / (<span class="hljs-type">float</span>)height;<br><br>    <span class="hljs-comment">//旋转中心</span><br>    u -= <span class="hljs-number">0.5f</span>;<br>    v -= <span class="hljs-number">0.5f</span>;<br>    <span class="hljs-type">float</span> tu = u * <span class="hljs-built_in">cosf</span>(theta) - v * <span class="hljs-built_in">sinf</span>(theta) + <span class="hljs-number">0.5f</span>;<br>    <span class="hljs-type">float</span> tv = v * <span class="hljs-built_in">cosf</span>(theta) - u * <span class="hljs-built_in">sinf</span>(theta) + <span class="hljs-number">0.5f</span>;<br><br>    <span class="hljs-comment">//read from texture to global memory</span><br>    <span class="hljs-comment">//tex2D是纹理采样函数</span><br>    output[y * width + x] = <span class="hljs-built_in">tex2D</span>&lt;<span class="hljs-type">float</span>&gt;(textObj, tu, tv);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">float</span>* h_data;<br>    <span class="hljs-type">int</span> width, height;<br>    <span class="hljs-type">float</span> angle;<br>    <span class="hljs-type">size_t</span> size = width * height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>);<br><br>    <span class="hljs-comment">//创建32位单通道浮点格式的CUDA数组</span><br>    <span class="hljs-comment">//CUDA数组是纹理内存的优化存储格式</span><br>    cudaChannelFormatDesc channelDesc = <br>                <span class="hljs-built_in">cudaCreateChannelDesc</span>(<span class="hljs-number">32</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, cudaChannelFormatKindFloat);<br>    <br>    cudaArray* cuArray;<br>    <span class="hljs-built_in">cudaMallocArray</span>(&amp;cuArray, &amp;channelDesc, width, height);<br><br>    <span class="hljs-comment">//copy host memory to device memory located at address h_data</span><br>    <span class="hljs-built_in">cudaMemcpyToArray</span>(cuArray, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, h_data, size, cudaMemcpyHostToDevice);<br><br>    <span class="hljs-comment">//texture</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaResourceDesc</span> resDesc;<br>    <span class="hljs-built_in">memset</span>(&amp;resDesc, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(resDesc));<br>    resDesc.resType = cudaResourceTypeArray;<br>    resDesc.res.array.array = cuArray;<br><br>    <span class="hljs-comment">//texture object parameters</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaTextureDesc</span> texDesc;<br>    <span class="hljs-built_in">memset</span>(&amp;texDesc, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(texDesc));<br>    texDesc.addressMode[<span class="hljs-number">0</span>] = cudaAddressModeWrap;<br>    texDesc.addressMode[<span class="hljs-number">1</span>] = cudaAddressModeWrap;<br>    texDesc.filterMode = cudaFilterModeLinear;<br>    texDesc.readMode = cudaReadModeElementType;<br>    texDesc.normalizedCoords = <span class="hljs-number">1</span>;<br><br>    <span class="hljs-comment">//creater texture object</span><br>    cudaTextureObject_t texobj = <span class="hljs-number">0</span>;<br>    <span class="hljs-built_in">cudaCreateTextureObject</span>(&amp;texobj, &amp;resDesc, &amp;texDesc, <span class="hljs-literal">NULL</span>);<br><br>    <span class="hljs-type">float</span>* output;<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;output, width * height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>    <span class="hljs-comment">//Invoke kernel</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">dimBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">dimGrid</span><span class="hljs-params">((width + dimBlock.x - <span class="hljs-number">1</span>) / dimBlock.x,</span></span><br><span class="hljs-params"><span class="hljs-function">                (height + dimBlock.y - <span class="hljs-number">1</span>) / dimBlock.y)</span></span>;<br><br>    transformKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt; (output, texobj, width, height, angle);<br><br>    <span class="hljs-comment">//destory texture obj</span><br>    <span class="hljs-built_in">cudaDestroyTextureObject</span>(texobj);<br><br>    <span class="hljs-comment">//free device memory</span><br>    <span class="hljs-built_in">cudaFreeArray</span>(cuArray);<br>    <span class="hljs-built_in">cudaFree</span>(output);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>纹理引用必须在文件作用域声明为静态全局变量，其基本语法为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">texture&lt;DataType, Type, ReadMode&gt; texRef;<br></code></pre></td></tr></table></figure>
<ol>
<li><strong>DataType</strong>：指定纹素(texel)的数据类型</li>
<li><strong>Type</strong>（可选，默认为<code>cudaTextureType1D</code>）：指定纹理类型：
<ul>
<li><code>cudaTextureType1D</code>：一维纹理</li>
<li><code>cudaTextureType2D</code>：二维纹理</li>
<li><code>cudaTextureType3D</code>：三维纹理</li>
<li><code>cudaTextureType1DLayered</code>：一维分层纹理</li>
<li><code>cudaTextureType2DLayered</code>：二维分层纹理</li>
</ul>
</li>
<li><strong>ReadMode</strong>（可选，默认为<code>cudaReadModeElementType</code>）：读取模式</li>
</ol>
<p>上述属性在编译时确定，不可更改，运行时可以更改的属性通过<code>textureReference</code>结构体定义：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">textureReference</span> &#123;<br>    <span class="hljs-type">int</span> normalized;  <span class="hljs-comment">// 是否使用归一化坐标</span><br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureFilterMode</span> filterMode;  <span class="hljs-comment">// 滤波模式</span><br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureAddressMode</span> addressMode[<span class="hljs-number">3</span>];  <span class="hljs-comment">// 寻址模式</span><br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaChannelFormatDesc</span> channelDesc;  <span class="hljs-comment">// 通道格式描述</span><br>    <span class="hljs-type">int</span> sRGB;  <span class="hljs-comment">// 是否使用sRGB色彩空间</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> maxAnisotropy;  <span class="hljs-comment">// 各向异性过滤的最大值</span><br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaTextureFilterMode</span> mipmapFilterMode;  <span class="hljs-comment">// Mipmap滤波模式</span><br>    <span class="hljs-type">float</span> mipmapLevelBias;  <span class="hljs-comment">// Mipmap级别偏置</span><br>    <span class="hljs-type">float</span> minMipmapLevelClamp;  <span class="hljs-comment">// 最小Mipmap级别钳制</span><br>    <span class="hljs-type">float</span> maxMipmapLevelClamp;  <span class="hljs-comment">// 最大Mipmap级别钳制</span><br>&#125;;<br></code></pre></td></tr></table></figure>
<p>在使用纹理引用前，必须将其绑定到内存或CUDA数组。</p>
<p>绑定到线性内存，使用低级API：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++">texture&lt;<span class="hljs-type">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;<br>textureReference* texRefPtr;<br><span class="hljs-built_in">cudaGetTextureReference</span>(&amp;texRefPtr, &amp;texRef);<br>cudaChannelFormatDesc channelDesc = <span class="hljs-built_in">cudaCreateChannelDesc</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-type">size_t</span> offset;<br><span class="hljs-built_in">cudaBindTexture2D</span>(&amp;offset, texRefPtr, devPtr, &amp;channelDesc, width, height, pitch);<br></code></pre></td></tr></table></figure>
<p>使用高级API：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++">texture&lt;<span class="hljs-type">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;<br>cudaChannelFormatDesc channelDesc = <span class="hljs-built_in">cudaCreateChannelDesc</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-type">size_t</span> offset;<br><span class="hljs-built_in">cudaBindTexture2D</span>(&amp;offset, texRef, devPtr, channelDesc, width, height, pitch);<br></code></pre></td></tr></table></figure>
<p>绑定到CUDA数组，使用低级API：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++">texture&lt;<span class="hljs-type">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;<br>textureReference* texRefPtr;<br><span class="hljs-built_in">cudaGetTextureReference</span>(&amp;texRefPtr, &amp;texRef);<br>cudaChannelFormatDesc channelDesc;<br><span class="hljs-built_in">cudaGetChannelDesc</span>(&amp;channelDesc, cuArray);<br><span class="hljs-built_in">cudaBindTextureToArray</span>(texRef, cuArray, &amp;channelDesc);<br></code></pre></td></tr></table></figure>
<p>使用高级API：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">texture&lt;<span class="hljs-type">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;<br><span class="hljs-built_in">cudaBindTextureToArray</span>(texRef, cuArray);<br></code></pre></td></tr></table></figure>
<p>使用如下命令解绑纹理：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaUnbindTexture</span>(texRef);<br></code></pre></td></tr></table></figure>
<p>对于上述旋转变换逻辑，使用纹理引用的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 2D float texture</span><br>texture&lt;<span class="hljs-type">float</span>, cudaTextureType2D, cudaReadModeElementType&gt; texRef;<br><br><span class="hljs-comment">// Simple transformation kernel</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">transformKernel</span><span class="hljs-params">(<span class="hljs-type">float</span>* output,</span></span><br><span class="hljs-params"><span class="hljs-function">                               <span class="hljs-type">int</span> width, </span></span><br><span class="hljs-params"><span class="hljs-function">                               <span class="hljs-type">int</span> height,</span></span><br><span class="hljs-params"><span class="hljs-function">                               <span class="hljs-type">float</span> theta)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// Calculate normalized texture coordinates</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <span class="hljs-type">float</span> u = x / (<span class="hljs-type">float</span>)width;<br>    <span class="hljs-type">float</span> v = y / (<span class="hljs-type">float</span>)height;<br><br>    <span class="hljs-comment">// Transform coordinates</span><br>    u -= <span class="hljs-number">0.5f</span>;<br>    v -= <span class="hljs-number">0.5f</span>;<br>    <span class="hljs-type">float</span> tu = u * <span class="hljs-built_in">cosf</span>(theta) - v * <span class="hljs-built_in">sinf</span>(theta) + <span class="hljs-number">0.5f</span>;<br>    <span class="hljs-type">float</span> tv = v * <span class="hljs-built_in">cosf</span>(theta) + u * <span class="hljs-built_in">sinf</span>(theta) + <span class="hljs-number">0.5f</span>;<br><br>    <span class="hljs-comment">// Read from texture and write to global memory</span><br>    output[y * width + x] = <span class="hljs-built_in">tex2D</span>(texRef, tu, tv);<br>&#125;<br><br><span class="hljs-comment">// Host code</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// Allocate CUDA array in device memory</span><br>    cudaChannelFormatDesc channelDesc =<br>        <span class="hljs-built_in">cudaCreateChannelDesc</span>(<span class="hljs-number">32</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>                             cudaChannelFormatKindFloat);<br>    cudaArray* cuArray;<br>    <span class="hljs-built_in">cudaMallocArray</span>(&amp;cuArray, &amp;channelDesc, width, height);<br><br>    <span class="hljs-comment">// Copy to device memory some data located at address h_data</span><br>    <span class="hljs-comment">// in host memory</span><br>    <span class="hljs-built_in">cudaMemcpyToArray</span>(cuArray, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, h_data, size,<br>                     cudaMemcpyHostToDevice);<br><br>    <span class="hljs-comment">// Set texture reference parameters</span><br>    texRef.addressMode[<span class="hljs-number">0</span>] = cudaAddressModeWrap;<br>    texRef.addressMode[<span class="hljs-number">1</span>] = cudaAddressModeWrap;<br>    texRef.filterMode = cudaFilterModeLinear;<br>    texRef.normalized = <span class="hljs-literal">true</span>;<br><br>    <span class="hljs-comment">// Bind the array to the texture reference</span><br>    <span class="hljs-built_in">cudaBindTextureToArray</span>(texRef, cuArray, channelDesc);<br><br>    <span class="hljs-comment">// Allocate result of transformation in device memory</span><br>    <span class="hljs-type">float</span>* output;<br>    <span class="hljs-built_in">cudaMalloc</span>(&amp;output, width * height * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>));<br><br>    <span class="hljs-comment">// Invoke kernel</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">dimBlock</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">dimGrid</span><span class="hljs-params">((width + dimBlock.x - <span class="hljs-number">1</span>) / dimBlock.x,</span></span><br><span class="hljs-params"><span class="hljs-function">                (height + dimBlock.y - <span class="hljs-number">1</span>) / dimBlock.y)</span></span>;<br>    transformKernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(output, width, height,<br>                                         angle);<br><br>    <span class="hljs-comment">// Free device memory</span><br>    <span class="hljs-built_in">cudaFreeArray</span>(cuArray);<br>    <span class="hljs-built_in">cudaFree</span>(output);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>CUDA C++没有直接的16位浮点数据类型，通过<code>unsigned short</code>类型进行转换，对于设备端的转换函数可以使用如下接口：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> __float2half_rn(<span class="hljs-type">float</span> f);  <span class="hljs-comment">// 32位浮点转16位</span><br><span class="hljs-type">float</span> __half2float(<span class="hljs-type">unsigned</span> <span class="hljs-type">short</span> h);    <span class="hljs-comment">// 16位转32位浮点</span><br></code></pre></td></tr></table></figure>
<p>对于主机端转换使用OpenEXR库中的等效函数。</p>
<p>以下是一些高级纹理特性的介绍：</p>
<p>**分层纹理（Layered Textures）**也被称为纹理数组（Texture Array）由多个相同维度、大小和数据类型的常规纹理层组成。</p>
<p>一维分层纹理使用一个整数索引(层)和一个浮点坐标(层内位置)寻址；二维分层纹理使用一个整数索引(层)和两个浮点坐标(层内位置)寻址。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMalloc3DArray</span>(&amp;cuArray, &amp;desc, <span class="hljs-built_in">make_cudaExtent</span>(width, height, <span class="hljs-number">0</span>), cudaArrayLayered);<br><br><span class="hljs-built_in">tex1DLayered</span>(texRef, x, layer);        <span class="hljs-comment">// 一维分层</span><br><span class="hljs-built_in">tex2DLayered</span>(texRef, x, y, layer);     <span class="hljs-comment">// 二维分层</span><br></code></pre></td></tr></table></figure>
<p>**立方体贴图（Cubemap Textures）**是特殊类型的二维分层纹理，有6层代表立方体的面，每层的宽度等于高度，使用三个坐标(x,y,z)作为方向向量进行寻址。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMalloc3DArray</span>(&amp;cuArray, &amp;desc, <span class="hljs-built_in">make_cudaExtent</span>(size, size, <span class="hljs-number">0</span>), cudaArrayCubemap);<br><br><span class="hljs-built_in">texCubemap</span>(texRef, x, y, z);<br></code></pre></td></tr></table></figure>
<p>立方体分层纹理（Cubemap layered Textures）由多个立方体贴图组成的序列,使用整数索引(选择立方体)和三个浮点坐标(立方体内位置)寻址.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaMalloc3DArray</span>(&amp;cuArray, &amp;desc, <span class="hljs-built_in">make_cudaExtent</span>(size, size, layers), <br>                 cudaArrayLayered | cudaArrayCubemap);<br>                 <br><span class="hljs-built_in">texCubemapLayered</span>(texRef, x, y, z, layer);<br></code></pre></td></tr></table></figure>
<h4 id="Surface-Memory">Surface Memory</h4>
<p>表面内存(Surface Memory)是CUDA中一种特殊的内存访问机制，主要用于计算能力2.0及以上的设备。它提供了对CUDA数组的直接读写能力，与纹理内存相比，表面内存更注重于随机访问和写入操作。</p>
<p>表面内存通过表面对象(Surface Object)或表面引用(Surface Reference)访问，支持读写操作（纹理内存通常只读），CUDA数组必须使用<code>cudaArraySurfaceLoadStore</code>标志创建。</p>
<p>表面对象是使用 cudaCreateSurfaceObject（） 从结构 cudaResourceDesc 类型的资源描述中创建，以下是一个表面对象的创建方式：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-function">cudaSurfaceObject_t <span class="hljs-title">createSurfaceObject</span><span class="hljs-params">(cudaArray* array)</span> </span>&#123;<br>    cudaResourceDesc resDesc;<br>    <span class="hljs-built_in">memset</span>(&amp;resDesc, <span class="hljs-number">0</span>, <span class="hljs-built_in">sizeof</span>(resDesc));<br>    resDesc.resType = cudaResourceTypeArray;<br>    resDesc.res.array.array = array;<br>    <br>    cudaSurfaceObject_t surfObj;<br>    <span class="hljs-built_in">cudaCreateSurfaceObject</span>(&amp;surfObj, &amp;resDesc);<br>    <span class="hljs-keyword">return</span> surfObj;<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaResourceDesc</span> &#123;<br>    <span class="hljs-keyword">enum</span> <span class="hljs-title class_">cudaResourceType</span> resType;  <span class="hljs-comment">// 资源类型</span><br>    <br>    <span class="hljs-keyword">union</span> &#123;<br>        <span class="hljs-keyword">struct</span> &#123;<br>            cudaArray_t array;      <span class="hljs-comment">// CUDA数组</span><br>        &#125; array;<br>        <br>        <span class="hljs-keyword">struct</span> &#123;<br>            cudaMipmappedArray_t mipmap;  <span class="hljs-comment">// Mipmap数组</span><br>        &#125; mipmap;<br>        <br>        <span class="hljs-keyword">struct</span> &#123;<br>            <span class="hljs-type">void</span>* devPtr;          <span class="hljs-comment">// 设备指针</span><br>            <span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaChannelFormatDesc</span> desc;  <span class="hljs-comment">// 通道格式</span><br>            <span class="hljs-type">size_t</span> sizeInBytes;     <span class="hljs-comment">// 大小（字节）</span><br>        &#125; linear;<br>        <br>        <span class="hljs-keyword">struct</span> &#123;<br>            <span class="hljs-type">void</span>* devPtr;          <span class="hljs-comment">// 设备指针</span><br>            <span class="hljs-keyword">struct</span> <span class="hljs-title class_">cudaChannelFormatDesc</span> desc;  <span class="hljs-comment">// 通道格式</span><br>            <span class="hljs-type">size_t</span> width;         <span class="hljs-comment">// 宽度</span><br>            <span class="hljs-type">size_t</span> height;        <span class="hljs-comment">// 高度</span><br>            <span class="hljs-type">size_t</span> pitchInBytes;  <span class="hljs-comment">// 间距（字节）</span><br>        &#125; pitch2D;<br>    &#125; res;<br>&#125;;<br></code></pre></td></tr></table></figure>
<p>表面内存通过一组内置函数进行访问:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">//一维表面</span><br><span class="hljs-built_in">surf1Dread</span>(T* data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x);<br><span class="hljs-built_in">surf1Dwrite</span>(T data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x);<br><br><span class="hljs-comment">//二维表面</span><br><span class="hljs-built_in">surf2Dread</span>(T* data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y);<br><span class="hljs-built_in">surf2Dwrite</span>(T data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y);<br><br><span class="hljs-comment">//三维表面</span><br><span class="hljs-built_in">surf3Dread</span>(T* data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> z);<br><span class="hljs-built_in">surf3Dwrite</span>(T data, cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> z);<br><br><span class="hljs-comment">//表面对象销毁</span><br><span class="hljs-built_in">cudaDestroySurfaceObject</span>(cudaSurfaceObject_t surfObj);<br></code></pre></td></tr></table></figure>
<p>以下是一个使用示例：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 创建CUDA数组</span><br>cudaArray* cuArray;<br>cudaChannelFormatDesc channelDesc = <span class="hljs-built_in">cudaCreateChannelDesc</span>&lt;<span class="hljs-type">float</span>&gt;();<br><span class="hljs-built_in">cudaMallocArray</span>(&amp;cuArray, &amp;channelDesc, width, height, cudaArraySurfaceLoadStore);<br><br><span class="hljs-comment">// 创建表面对象</span><br>cudaSurfaceObject_t surfObj = <span class="hljs-built_in">createSurfaceObject</span>(cuArray);<br><br><span class="hljs-comment">// 内核函数：写入表面</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">writeSurface</span><span class="hljs-params">(cudaSurfaceObject_t surfObj, <span class="hljs-type">int</span> width, <span class="hljs-type">int</span> height)</span> </span>&#123;<br>    <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <br>    <span class="hljs-keyword">if</span> (x &lt; width &amp;&amp; y &lt; height) &#123;<br>        <span class="hljs-type">float</span> value = x + y * <span class="hljs-number">0.1f</span>;<br>        <span class="hljs-built_in">surf2Dwrite</span>(value, surfObj, x, y);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 调用内核</span><br><span class="hljs-function">dim3 <span class="hljs-title">blocks</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br><span class="hljs-function">dim3 <span class="hljs-title">grids</span><span class="hljs-params">((width + blocks.x - <span class="hljs-number">1</span>) / blocks.x, (height + blocks.y - <span class="hljs-number">1</span>) / blocks.y)</span></span>;<br>writeSurface&lt;&lt;&lt;grids, blocks&gt;&gt;&gt;(surfObj, width, height);<br><br><span class="hljs-comment">// 清理</span><br><span class="hljs-built_in">cudaDestroySurfaceObject</span>(surfObj);<br><span class="hljs-built_in">cudaFreeArray</span>(cuArray);<br></code></pre></td></tr></table></figure>
<h3 id="图像互作性">图像互作性</h3>
<p>CUDA与OpenGL以及Direct3D等的互操作性允许GPU资源在图形渲染和通用计算之间共享，避免了数据在CPU内存中的来回拷贝，显著提高了异构计算的效率</p>
<p>操作流程如下：</p>
<ol>
<li><strong>资源注册</strong>：将OpenGL资源注册为CUDA可访问资源</li>
<li><strong>资源映射</strong>：将注册的资源映射到CUDA地址空间</li>
<li><strong>CUDA访问</strong>：通过CUDA内核读写资源</li>
<li><strong>资源解映射</strong>：解除CUDA对资源的访问</li>
<li><strong>OpenGL使用</strong>：OpenGL使用修改后的资源进行渲染</li>
<li><strong>资源注销</strong>：程序结束时注销资源</li>
</ol>
<p>与OpenGL的互作，关键API函数如下：</p>
<p>1.资源的注册</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function">cudaError_t <span class="hljs-title">cudaGraphicsGLRegisterBuffer</span><span class="hljs-params">(</span></span><br><span class="hljs-params"><span class="hljs-function">    cudaGraphicsResource** resource,</span></span><br><span class="hljs-params"><span class="hljs-function">    GLuint buffer,</span></span><br><span class="hljs-params"><span class="hljs-function">    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> flags)</span></span>;<br></code></pre></td></tr></table></figure>
<ul>
<li><code>resource</code>：返回的CUDA图形资源指针</li>
<li><code>buffer</code>：OpenGL缓冲区对象名称</li>
<li><code>flags</code>：注册标志，常用值：
<ul>
<li><code>cudaGraphicsRegisterFlagsNone</code>：默认</li>
<li><code>cudaGraphicsRegisterFlagsReadOnly</code>：只读</li>
<li><code>cudaGraphicsRegisterFlagsWriteDiscard</code>：只写（丢弃原有内容）</li>
<li><code>cudaGraphicsRegisterFlagsSurfaceLoadStore</code>：允许表面读写</li>
</ul>
</li>
</ul>
<p>2.资源的映射与解映射</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-built_in">cudaGraphicsMapResources</span>(<span class="hljs-type">int</span> count, cudaGraphicsResource_t* resources, cudaStream_t stream);<br><span class="hljs-built_in">cudaGraphicsUnmapResources</span>(<span class="hljs-type">int</span> count, cudaGraphicsResource_t* resources, cudaStream_t stream);<br></code></pre></td></tr></table></figure>
<p>3.获取映射指针</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaGraphicsResourceGetMappedPointer</span>(<span class="hljs-type">void</span>** devPtr, <span class="hljs-type">size_t</span>* size, cudaGraphicsResource_t resource);<br></code></pre></td></tr></table></figure>
<p>以下是一个完整的示例，显示一个动态正弦波图案，由CUDA计算顶点位置并且通过OpenGL渲染：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;GL/glew.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;GL/freeglut.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_runtime.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cuda_gl_interop.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><br><span class="hljs-type">const</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> WIDTH = <span class="hljs-number">800</span>;<br><span class="hljs-type">const</span> <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> HEIGHT = <span class="hljs-number">600</span>;<br><br>GLuint positionsVBO;<br>cudaGraphicsResource* positionsVBO_CUDA = <span class="hljs-literal">nullptr</span>;<br><span class="hljs-type">float</span> animTime = <span class="hljs-number">0.0f</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__)</span><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">check</span><span class="hljs-params">(cudaError_t result, <span class="hljs-type">const</span> <span class="hljs-type">char</span>* <span class="hljs-type">const</span> func, <span class="hljs-type">const</span> <span class="hljs-type">char</span>* <span class="hljs-type">const</span> file, <span class="hljs-type">int</span> line)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (result != cudaSuccess) &#123;<br>        std::cerr &lt;&lt; <span class="hljs-string">&quot;CUDA error at &quot;</span> &lt;&lt; file &lt;&lt; <span class="hljs-string">&quot;:&quot;</span> &lt;&lt; line &lt;&lt; <span class="hljs-string">&quot; code=&quot;</span> &lt;&lt; result <br>                  &lt;&lt; <span class="hljs-string">&quot; \&quot;&quot;</span> &lt;&lt; <span class="hljs-built_in">cudaGetErrorString</span>(result) &lt;&lt; <span class="hljs-string">&quot;\&quot; &quot;</span><br>                  &lt;&lt; func &lt;&lt; std::endl;<br>        <span class="hljs-built_in">exit</span>(EXIT_FAILURE);<br>    &#125;<br>&#125;<br><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">createVertices</span><span class="hljs-params">(float4* positions, <span class="hljs-type">float</span> time, </span></span><br><span class="hljs-params"><span class="hljs-function">                             <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> width, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> height)</span> </span>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x = blockIdx.x * blockDim.x + threadIdx.x;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> y = blockIdx.y * blockDim.y + threadIdx.y;<br>    <br>    <span class="hljs-keyword">if</span> (x &lt; width &amp;&amp; y &lt; height) &#123;  <span class="hljs-comment">// 添加边界检查</span><br>        <span class="hljs-type">float</span> u = x / (<span class="hljs-type">float</span>)width;<br>        <span class="hljs-type">float</span> v = y / (<span class="hljs-type">float</span>)height;<br>        u = u * <span class="hljs-number">2.0f</span> - <span class="hljs-number">1.0f</span>;<br>        v = v * <span class="hljs-number">2.0f</span> - <span class="hljs-number">1.0f</span>;<br>        <br>        <span class="hljs-type">float</span> freq = <span class="hljs-number">4.0f</span>;<br>        <span class="hljs-type">float</span> w = <span class="hljs-built_in">sinf</span>(u * freq + time) * <span class="hljs-built_in">cosf</span>(v * freq + time) * <span class="hljs-number">0.5f</span>;<br>        <br>        positions[y * width + x] = <span class="hljs-built_in">make_float4</span>(u, w, v, <span class="hljs-number">1.0f</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">init</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 初始化OpenGL缓冲区和CUDA互操作</span><br>    <span class="hljs-built_in">glClearColor</span>(<span class="hljs-number">0.0f</span>, <span class="hljs-number">0.0f</span>, <span class="hljs-number">0.0f</span>, <span class="hljs-number">1.0f</span>);<br>    <span class="hljs-built_in">glPointSize</span>(<span class="hljs-number">1.0f</span>);<br>    <br>    <span class="hljs-built_in">glGenBuffers</span>(<span class="hljs-number">1</span>, &amp;positionsVBO);<br>    <span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, positionsVBO);<br>    <span class="hljs-built_in">glBufferData</span>(GL_ARRAY_BUFFER, WIDTH * HEIGHT * <span class="hljs-built_in">sizeof</span>(float4), <span class="hljs-literal">nullptr</span>, GL_DYNAMIC_DRAW);<br>    <span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, <span class="hljs-number">0</span>);<br><br>    <span class="hljs-comment">// 检查设备是否支持CUDA-OpenGL互操作</span><br>    cudaDeviceProp prop;<br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>));<br>    <span class="hljs-keyword">if</span> (!prop.canMapHostMemory || !prop.unifiedAddressing) &#123;<br>        std::cerr &lt;&lt; <span class="hljs-string">&quot;Device does not support required features for interop&quot;</span> &lt;&lt; std::endl;<br>        <span class="hljs-built_in">exit</span>(EXIT_FAILURE);<br>    &#125;<br><br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaGraphicsGLRegisterBuffer</span>(&amp;positionsVBO_CUDA,<br>                                                positionsVBO,<br>                                                cudaGraphicsMapFlagsWriteDiscard));<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">display</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-comment">// 确保OpenGL上下文正确</span><br>    <span class="hljs-built_in">glutSetWindow</span>(<span class="hljs-built_in">glutGetWindow</span>());<br>    <br>    <span class="hljs-comment">// 解除所有可能影响互操作的OpenGL绑定</span><br>    <span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, <span class="hljs-number">0</span>);<br>    <br>    <span class="hljs-comment">// 映射资源</span><br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaGraphicsMapResources</span>(<span class="hljs-number">1</span>, &amp;positionsVBO_CUDA, <span class="hljs-number">0</span>));<br>    <br>    float4* d_positions = <span class="hljs-literal">nullptr</span>;<br>    <span class="hljs-type">size_t</span> num_bytes;<br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaGraphicsResourceGetMappedPointer</span>(<br>        (<span class="hljs-type">void</span>**)&amp;d_positions, &amp;num_bytes, positionsVBO_CUDA));<br><br>    <span class="hljs-comment">// 执行内核</span><br>    <span class="hljs-function">dim3 <span class="hljs-title">block</span><span class="hljs-params">(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>)</span></span>;<br>    <span class="hljs-function">dim3 <span class="hljs-title">grid</span><span class="hljs-params">((WIDTH + block.x - <span class="hljs-number">1</span>) / block.x, </span></span><br><span class="hljs-params"><span class="hljs-function">              (HEIGHT + block.y - <span class="hljs-number">1</span>) / block.y)</span></span>;<br>    createVertices&lt;&lt;&lt;grid, block&gt;&gt;&gt;(d_positions, animTime, WIDTH, HEIGHT);<br>    <br>    <span class="hljs-comment">// 确保内核执行完成</span><br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaDeviceSynchronize</span>());<br>    <br>    <span class="hljs-comment">// 解映射资源</span><br>    <span class="hljs-built_in">CHECK_CUDA_ERROR</span>(<span class="hljs-built_in">cudaGraphicsUnmapResources</span>(<span class="hljs-number">1</span>, &amp;positionsVBO_CUDA, <span class="hljs-number">0</span>));<br>    <br>    <span class="hljs-comment">// 渲染</span><br>    <span class="hljs-built_in">glClear</span>(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);<br>    <span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, positionsVBO);<br>    <span class="hljs-built_in">glVertexPointer</span>(<span class="hljs-number">4</span>, GL_FLOAT, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<br>    <span class="hljs-built_in">glEnableClientState</span>(GL_VERTEX_ARRAY);<br>    <span class="hljs-built_in">glDrawArrays</span>(GL_POINTS, <span class="hljs-number">0</span>, WIDTH * HEIGHT);<br>    <span class="hljs-built_in">glDisableClientState</span>(GL_VERTEX_ARRAY);<br>    <span class="hljs-built_in">glBindBuffer</span>(GL_ARRAY_BUFFER, <span class="hljs-number">0</span>);  <span class="hljs-comment">// 解除绑定</span><br>    <br>    <span class="hljs-built_in">glutSwapBuffers</span>();<br>    <span class="hljs-built_in">glutPostRedisplay</span>();<br>    <br>    animTime += <span class="hljs-number">0.01f</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">cleanup</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (positionsVBO_CUDA) &#123;<br>        <span class="hljs-built_in">cudaGraphicsUnregisterResource</span>(positionsVBO_CUDA);<br>        positionsVBO_CUDA = <span class="hljs-literal">nullptr</span>;<br>    &#125;<br>    <br>    <span class="hljs-keyword">if</span> (positionsVBO) &#123;<br>        <span class="hljs-built_in">glDeleteBuffers</span>(<span class="hljs-number">1</span>, &amp;positionsVBO);<br>        positionsVBO = <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">keyboard</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> key, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123;<br>    <span class="hljs-keyword">if</span> (key == <span class="hljs-number">27</span>) &#123;  <span class="hljs-comment">// ESC键</span><br>        <span class="hljs-built_in">cleanup</span>();<br>        <span class="hljs-built_in">exit</span>(EXIT_SUCCESS);<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>** argv)</span> </span>&#123;<br>    <span class="hljs-built_in">glutInit</span>(&amp;argc, argv);<br>    <span class="hljs-built_in">glutInitDisplayMode</span>(GLUT_DOUBLE | GLUT_RGBA | GLUT_DEPTH);<br>    <span class="hljs-built_in">glutInitWindowSize</span>(WIDTH, HEIGHT);<br>    <span class="hljs-type">int</span> window = <span class="hljs-built_in">glutCreateWindow</span>(<span class="hljs-string">&quot;CUDA-OpenGL Interop Demo&quot;</span>);<br>    <br>    <span class="hljs-comment">// 必须在创建窗口后初始化GLEW</span><br>    glewExperimental = GL_TRUE;<br>    GLenum err = <span class="hljs-built_in">glewInit</span>();<br>    <span class="hljs-keyword">if</span> (err != GLEW_OK) &#123;<br>        std::cerr &lt;&lt; <span class="hljs-string">&quot;GLEW init failed: &quot;</span> &lt;&lt; <span class="hljs-built_in">glewGetErrorString</span>(err) &lt;&lt; std::endl;<br>        <span class="hljs-keyword">return</span> EXIT_FAILURE;<br>    &#125;<br>    <br>    <span class="hljs-comment">// 检查必要扩展</span><br>    <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">glewIsSupported</span>(<span class="hljs-string">&quot;GL_VERSION_2_0&quot;</span>)) &#123;<br>        std::cerr &lt;&lt; <span class="hljs-string">&quot;OpenGL 2.0 not supported&quot;</span> &lt;&lt; std::endl;<br>        <span class="hljs-keyword">return</span> EXIT_FAILURE;<br>    &#125;<br><br>    <span class="hljs-built_in">init</span>();<br>    <br>    <span class="hljs-built_in">glutDisplayFunc</span>(display);<br>    <span class="hljs-built_in">glutKeyboardFunc</span>(keyboard);<br>    <span class="hljs-built_in">glutCloseFunc</span>(cleanup);  <span class="hljs-comment">// 确保退出时清理</span><br>    <br>    <span class="hljs-built_in">glutMainLoop</span>();<br>    <span class="hljs-keyword">return</span> EXIT_SUCCESS;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>确保安装OpenGL开发库(GLEW和FreeGLUT)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get install -y libglew-dev freeglut3-dev<br></code></pre></td></tr></table></figure>
<p>使用如下编译命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc -o cuda_gl_interop cuda_gl_interop.cu -lGL -lGLEW -lglut<br></code></pre></td></tr></table></figure>
<p>CUDA支持的Direct3D版本：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Direct3D版本</th>
<th style="text-align:left">关键创建参数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">D3D9Ex</td>
<td style="text-align:left"><code>DeviceType = D3DDEVTYPE_HAL</code> <code>BehaviorFlags = D3DCREATE_HARDWARE_VERTEXPROCESSING</code></td>
</tr>
<tr>
<td style="text-align:left">D3D10/D3D11</td>
<td style="text-align:left"><code>DriverType = D3D_DRIVER_TYPE_HARDWARE</code></td>
</tr>
</tbody>
</table>
<p>使用如下注册函数：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Direct3D版本</th>
<th style="text-align:left">注册函数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">D3D9Ex</td>
<td style="text-align:left"><code>cudaGraphicsD3D9RegisterResource()</code></td>
</tr>
<tr>
<td style="text-align:left">D3D10</td>
<td style="text-align:left"><code>cudaGraphicsD3D10RegisterResource()</code></td>
</tr>
<tr>
<td style="text-align:left">D3D11</td>
<td style="text-align:left"><code>cudaGraphicsD3D11RegisterResource()</code></td>
</tr>
</tbody>
</table>
<p>在配备多个NVIDIA GPU的系统中，CUDA将每个物理GPU视为独立的计算设备（device），每个设备有独立的设备ID。但在SLI（Scalable Link Interface）配置下，GPU间的协同工作会带来特殊考量：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">int</span> deviceCount;<br><span class="hljs-built_in">cudaGetDeviceCount</span>(&amp;deviceCount); <span class="hljs-comment">// 获取系统中CUDA设备总数</span><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; deviceCount; i++) &#123;<br>    cudaDeviceProp prop;<br>    <span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, i); <span class="hljs-comment">// 获取每个设备的详细属性</span><br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;GPU %d: %s\n&quot;</span>, i, prop.name);<br>&#125;<br></code></pre></td></tr></table></figure>
<p>在SLI配置中，当通过Direct3D或OpenGL分配资源时，内存会在所有SLI组内的GPU上同步分配：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 典型的内存分配失败场景示例</span><br>cudaError_t err = <span class="hljs-built_in">cudaMalloc</span>(&amp;devPtr, size);<br><span class="hljs-keyword">if</span> (err == cudaErrorMemoryAllocation) &#123;<br>    <span class="hljs-comment">// 在SLI配置下可能比预期更早触发内存不足错误</span><br>&#125;<br></code></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">场景</th>
<th style="text-align:left">推荐设备选择方法</th>
<th style="text-align:left">优点</th>
<th style="text-align:left">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单帧渲染</td>
<td style="text-align:left">cudaD3D11DeviceListCurrentFrame</td>
<td style="text-align:left">最小化数据传输</td>
<td style="text-align:left">需要频繁切换</td>
</tr>
<tr>
<td style="text-align:left">多帧并行</td>
<td style="text-align:left">轮询分配</td>
<td style="text-align:left">负载均衡</td>
<td style="text-align:left">增加同步复杂度</td>
</tr>
<tr>
<td style="text-align:left">数据并行</td>
<td style="text-align:left">固定设备分配</td>
<td style="text-align:left">实现简单</td>
<td style="text-align:left">可能造成瓶颈</td>
</tr>
</tbody>
</table>
<p>CUDA外部资源互操作性允许CUDA导入由其他API显式导出的资源，实现跨API的高效资源共享。这种机制避免了数据拷贝，特别适用于以下场景：</p>
<ul>
<li>与图形API（如OpenGL/Vulkan/Direct3D）共享纹理和缓冲区</li>
<li>与视频处理API（如NVDEC/NVENC）共享视频帧</li>
<li>实现多进程GPU资源共享</li>
<li>与计算框架（如OpenCL）进行互操作</li>
</ul>
<p><img src="%E5%86%85%E5%AD%98%E5%AF%BC%E5%85%A5%E6%B5%81%E7%A8%8B.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="内存导入流程" /></p>
<p>有如下关键的API：</p>
<p>1.内存导入：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">cudaExternalMemoryHandleDesc desc = &#123;&#125;;<br>desc.type = cudaExternalMemoryHandleTypeOpaqueWin32;  <span class="hljs-comment">// Windows句柄类型</span><br>desc.handle.win<span class="hljs-number">32.</span>handle = externalHandle;            <span class="hljs-comment">// 外部句柄</span><br>desc.size = allocationSize;                           <span class="hljs-comment">// 内存大小</span><br><br>cudaExternalMemory_t extMem;<br><span class="hljs-built_in">cudaImportExternalMemory</span>(&amp;extMem, &amp;desc);<br></code></pre></td></tr></table></figure>
<p>2.获取映射缓冲区</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C++">cudaExternalMemoryBufferDesc bufDesc = &#123;&#125;;<br>bufDesc.offset = <span class="hljs-number">0</span>;      <span class="hljs-comment">// 内存偏移</span><br>bufDesc.size = dataSize;  <span class="hljs-comment">// 映射大小</span><br>bufDesc.flags = <span class="hljs-number">0</span>;        <span class="hljs-comment">// 标志位</span><br><br><span class="hljs-type">void</span>* devPtr;<br><span class="hljs-built_in">cudaExternalMemoryGetMappedBuffer</span>(&amp;devPtr, extMem, &amp;bufDesc);<br></code></pre></td></tr></table></figure>
<p>3.资源清理</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">cudaFree</span>(devPtr);                   <span class="hljs-comment">// 先释放映射</span><br><span class="hljs-built_in">cudaDestroyExternalMemory</span>(extMem);  <span class="hljs-comment">// 再销毁外部内存</span><br></code></pre></td></tr></table></figure>
<p>进行同步对象互操作时，支持的类型如下：</p>
<table>
<thead>
<tr>
<th style="text-align:left">同步类型</th>
<th style="text-align:left">支持平台</th>
<th style="text-align:left">特性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Opaque FD</td>
<td style="text-align:left">Linux</td>
<td style="text-align:left">文件描述符形式</td>
</tr>
<tr>
<td style="text-align:left">Opaque Win32</td>
<td style="text-align:left">Windows</td>
<td style="text-align:left">NT句柄形式</td>
</tr>
<tr>
<td style="text-align:left">NVIDIA SCI</td>
<td style="text-align:left">跨平台</td>
<td style="text-align:left">高性能NVIDIA专用接口</td>
</tr>
</tbody>
</table>
<p>整体的信号量工作流程如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 导入信号量</span><br>cudaExternalSemaphoreHandleDesc semDesc = &#123;&#125;;<br>semDesc.type = cudaExternalSemaphoreHandleTypeOpaqueWin32;<br>semDesc.handle.win<span class="hljs-number">32.</span>handle = semaphoreHandle;<br><br>cudaExternalSemaphore_t extSem;<br><span class="hljs-built_in">cudaImportExternalSemaphore</span>(&amp;extSem, &amp;semDesc);<br><br><span class="hljs-comment">// 信号操作序列</span><br>cudaStream_t stream;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream);<br><br><span class="hljs-comment">// Vulkan完成写入后，CUDA等待信号</span><br>cudaExternalSemaphoreWaitParams waitParams = &#123;&#125;;<br>waitParams.params.fence.value = <span class="hljs-number">0</span>;  <span class="hljs-comment">// 同步值</span><br><span class="hljs-built_in">cudaWaitExternalSemaphoresAsync</span>(&amp;extSem, &amp;waitParams, <span class="hljs-number">1</span>, stream);<br><br><span class="hljs-comment">// CUDA计算任务</span><br>myKernel&lt;&lt;&lt;..., stream&gt;&gt;&gt;(...);<br><br><span class="hljs-comment">// CUDA完成后触发信号</span><br>cudaExternalSemaphoreSignalParams signalParams = &#123;&#125;;<br>signalParams.params.fence.value = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">cudaSignalExternalSemaphoresAsync</span>(&amp;extSem, &amp;signalParams, <span class="hljs-number">1</span>, stream);<br></code></pre></td></tr></table></figure>
<p><img src="%E8%B7%A8API%E5%90%8C%E6%AD%A5%E6%A8%A1%E5%BC%8F.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="跨API同步模式" /></p>
<p><strong>Windows平台(NT句柄)</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 安全属性设置</span><br>SECURITY_ATTRIBUTES sa = &#123;&#125;;<br>sa.nLength = <span class="hljs-built_in">sizeof</span>(sa);<br>sa.bInheritHandle = TRUE;  <span class="hljs-comment">// 允许继承</span><br><br><span class="hljs-comment">// 创建可导出资源</span><br>HANDLE handle;<br>cudaExternalMemoryHandleDesc desc = &#123;&#125;;<br>desc.type = cudaExternalMemoryHandleTypeOpaqueWin32;<br>desc.handle.win<span class="hljs-number">32.</span>handle = handle;<br>desc.flags = cudaExternalMemoryDedicated;  <span class="hljs-comment">// 专用内存标志</span><br></code></pre></td></tr></table></figure>
<p><strong>Linux平台(文件描述符)</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 导出FD</span><br><span class="hljs-type">int</span> fd = <span class="hljs-built_in">exportVulkanMemoryToFD</span>();<br><br>cudaExternalMemoryHandleDesc desc = &#123;&#125;;<br>desc.type = cudaExternalMemoryHandleTypeOpaqueFd;<br>desc.handle.fd = fd;<br>desc.size = memSize;<br></code></pre></td></tr></table></figure>
<p><strong>NVIDIA SCI(高性能互连)</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 使用NVIDIA专用接口</span><br>cudaExternalMemoryHandleDesc desc = &#123;&#125;;<br>desc.type = cudaExternalMemoryHandleTypeNvSciBuf;<br>desc.handle.nvSciBufObject = nvSciBufObj;<br></code></pre></td></tr></table></figure>
<h2 id="CUDA硬件实现">CUDA硬件实现</h2>
<p>NVIDIA显卡的核心是由许多&quot;流式多处理器&quot;(SM)组成的阵列。当CPU启动一个CUDA计算任务时：</p>
<ul>
<li>计算任务被分成多个&quot;线程块&quot;</li>
<li>这些块会被分配到空闲的SM上执行</li>
<li>每个SM可以同时运行多个线程块</li>
<li>当一个块完成时，新的块会立即补上、</li>
</ul>
<p>每个SM需要同时处理数百个线程，为此NVIDIA发明了独特的&quot;SIMT&quot;(单指令多线程)技术，SIMT相较于CPU有如下区别：</p>
<table>
<thead>
<tr>
<th style="text-align:left">特性</th>
<th style="text-align:left">CPU</th>
<th style="text-align:left">GPU(SIMT)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">执行方式</td>
<td style="text-align:left">一次处理1个线程</td>
<td style="text-align:left">一次处理32个线程(1个warp)</td>
</tr>
<tr>
<td style="text-align:left">分支预测</td>
<td style="text-align:left">有</td>
<td style="text-align:left">无</td>
</tr>
<tr>
<td style="text-align:left">线程切换</td>
<td style="text-align:left">开销大</td>
<td style="text-align:left">零开销</td>
</tr>
<tr>
<td style="text-align:left">适合场景</td>
<td style="text-align:left">复杂逻辑</td>
<td style="text-align:left">大批量简单计算</td>
</tr>
</tbody>
</table>
<p>Warp，称之为线程束，就像纺织中的&quot;经线束&quot;一样，32个线程捆绑成一组执行，所有线程同时开始执行相同指令，但每个线程有自己的数据和执行路径。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 示例：查看warp大小</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">showWarpSize</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-keyword">if</span>(threadIdx.x == <span class="hljs-number">0</span>) &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;1个warp包含%d个线程\n&quot;</span>, warpSize); <span class="hljs-comment">// 总是32</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>尽量确保一个warp中的32个线程走相同的路径：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 高效访问：32个线程连续读取内存</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">goodMemoryAccess</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input)</span> </span>&#123;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    output[i] = input[i]; <span class="hljs-comment">// 像军训排队一样整齐</span><br>&#125;<br><br><span class="hljs-comment">// 低效访问：线程跳跃式访问</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">badMemoryAccess</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input)</span> </span>&#123;<br>    <span class="hljs-type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;<br>    output[i*<span class="hljs-number">10</span>] = input[i*<span class="hljs-number">10</span>]; <span class="hljs-comment">// 像散兵游勇</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>为了避免降低warp效率，我们可以采用一些策略：</p>
<p>1.减少分叉</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 优化前：可能造成warp分叉</span><br><span class="hljs-keyword">if</span>(index % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// A路径</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-comment">// B路径</span><br>&#125;<br><br><span class="hljs-comment">// 优化后：减少分叉</span><br>result = (index % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) ? <span class="hljs-built_in">calcA</span>() : <span class="hljs-built_in">calcB</span>();<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>自动配置资源</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 自动计算最佳配置</span><br><span class="hljs-type">int</span> blockSize;   <span class="hljs-comment">// 每个块的线程数</span><br><span class="hljs-type">int</span> minGridSize; <span class="hljs-comment">// 最少需要多少个块</span><br><span class="hljs-built_in">cudaOccupancyCalculateBestBlockSize</span>(&amp;blockSize, &amp;minGridSize, myKernel);<br></code></pre></td></tr></table></figure>
<p>可以执行调试命令查看相关性能：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看warp执行效率</span><br>nvprof --metrics achieved_occupancy ./myApp<br><br><span class="hljs-comment"># 检查内存访问模式</span><br>nsight-compute --<span class="hljs-built_in">set</span> default --section MemoryWorkloadAnalysis ./myApp<br></code></pre></td></tr></table></figure>
<p>GPU的流式多处理器(SM)采用独特的<strong>硬件级上下文管理</strong>：</p>
<ul>
<li>每个warp的完整执行状态（程序计数器、寄存器等）始终保存在芯片上</li>
<li>切换不同warp的执行<strong>不需要保存/恢复上下文</strong></li>
<li>硬件调度器每个时钟周期选择就绪warp发射指令</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// 示例：查看当前设备的warp调度器数量</span><br>cudaDeviceProp prop;<br><span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;每个SM的warp调度器数量: %d\n&quot;</span>, prop.maxThreadsPerMultiProcessor / <span class="hljs-number">32</span>);<br></code></pre></td></tr></table></figure>
<p>SM资源分区模型由以下几种类型：</p>
<table>
<thead>
<tr>
<th style="text-align:left">资源类型</th>
<th style="text-align:left">分配单位</th>
<th style="text-align:left">特性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">寄存器文件</td>
<td style="text-align:left">每个线程</td>
<td style="text-align:left">最快的存储，生命周期随线程</td>
</tr>
<tr>
<td style="text-align:left">共享内存</td>
<td style="text-align:left">每个线程块</td>
<td style="text-align:left">块内线程共享，手动管理</td>
</tr>
<tr>
<td style="text-align:left">L1缓存/纹理缓存</td>
<td style="text-align:left">整个SM</td>
<td style="text-align:left">自动缓存</td>
</tr>
</tbody>
</table>
<p>对于特定的资源，有其合理的分配方式：</p>
<p>每个块的warp数量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">warps_per_block = ceil(threads_per_block, 32) / 32<br></code></pre></td></tr></table></figure>
<p>寄存器分配：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">总寄存器 = 每个线程寄存器数 × 线程数 × warp数量<br></code></pre></td></tr></table></figure>
<p>共享内存分配：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">__shared__ <span class="hljs-built_in">float</span> tile[32][32]; // 静态分配<br>extern __shared__ int dynamic[]; // 动态分配<br></code></pre></td></tr></table></figure>
<h2 id="CUDA性能指南">CUDA性能指南</h2>
<p>性能优化围绕三个基本策略展开：</p>
<ul>
<li>最大化并行执行以实现最大利用率</li>
<li>优化内存使用以实现最大内存吞吐量</li>
<li>优化指令使用以实现最大的指令吞吐量</li>
</ul>
<h3 id="最大化利用率">最大化利用率</h3>
<p>为了最大限度地提高利用率，应用程序的结构应尽可能多地公开并行性，并有效地将这种并行性映射到系统的各个组件，以使它们在大部分时间都保持忙碌。</p>
<p>在<strong>应用层面</strong>的高层设计上，应用程序应通过异步函数调用和流(stream)技术，最大化主机(CPU)、设备(GPU)以及连接总线之间的并行执行。基本原则是：</p>
<ul>
<li>CPU处理串行任务</li>
<li>GPU处理并行任务</li>
</ul>
<p>对于需要线程间数据同步的并行任务，存在两种情况：</p>
<ol>
<li>
<p><strong>同一线程块内同步</strong>：使用<code>__syncthreads()</code>和共享内存</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__shared__ <span class="hljs-type">float</span> temp[<span class="hljs-number">32</span>];  <span class="hljs-comment">// 共享内存</span><br>temp[threadIdx.x] = data;<br>__syncthreads();           <span class="hljs-comment">// 块内同步</span><br></code></pre></td></tr></table></figure>
</li>
<li>
<p><strong>跨线程块同步</strong>：必须通过全局内存和多次内核调用实现（效率较低）</p>
</li>
</ol>
<p>在<strong>设备内部</strong>，应最大化多处理器(SM)间的并行执行：</p>
<ul>
<li>通过流(stream)实现多内核并发执行：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp">cudaStream_t stream1, stream2;<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream1);<br><span class="hljs-built_in">cudaStreamCreate</span>(&amp;stream2);<br>kernel1&lt;&lt;&lt;..., stream1&gt;&gt;&gt;();<br>kernel2&lt;&lt;&lt;..., stream2&gt;&gt;&gt;();<br></code></pre></td></tr></table></figure>
<p>在<strong>多处理器层面</strong>，每个SM内部，应最大化各功能单元的并行利用率：</p>
<ul>
<li><strong>Warp调度</strong>：每个时钟周期选择就绪的warp执行指令</li>
<li><strong>延迟隐藏</strong>：通过足够多的活跃warp掩盖指令延迟</li>
<li><strong>计算能力差异</strong>：
<ul>
<li>5.x/6.1/7.x设备：需要4×延迟周期数的warp</li>
<li>6.0设备：需要2×延迟周期数的warp</li>
<li>3.x设备：需要8×延迟周期数的warp</li>
</ul>
</li>
</ul>
<p>CUDA提供API帮助优化线程块配置：</p>
<p>占用率计算示例：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 设备代码</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">MyKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *d, <span class="hljs-type">int</span> *a, <span class="hljs-type">int</span> *b)</span> </span>&#123;<br>    <span class="hljs-type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;<br>    d[idx] = a[idx] * b[idx];<br>&#125;<br><br><span class="hljs-comment">// 主机代码</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span>&#123;<br>    <span class="hljs-type">int</span> numBlocks, blockSize = <span class="hljs-number">32</span>;<br>    cudaDeviceProp prop;<br>    <span class="hljs-built_in">cudaGetDeviceProperties</span>(&amp;prop, <span class="hljs-number">0</span>);<br>    <br>    <span class="hljs-comment">// 计算占用率</span><br>    <span class="hljs-built_in">cudaOccupancyMaxActiveBlocksPerMultiprocessor</span>(<br>        &amp;numBlocks, MyKernel, blockSize, <span class="hljs-number">0</span>);<br>    <br>    <span class="hljs-type">float</span> occupancy = (numBlocks * blockSize / prop.warpSize) / <br>                    (<span class="hljs-type">float</span>)(prop.maxThreadsPerMultiProcessor / prop.warpSize);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;占用率: %.1f%%\n&quot;</span>, occupancy * <span class="hljs-number">100</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>自动配置启动参数：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">launchKernel</span><span class="hljs-params">(<span class="hljs-type">int</span> *array, <span class="hljs-type">int</span> count)</span> </span>&#123;<br>    <span class="hljs-type">int</span> blockSize, minGridSize, gridSize;<br>    <br>    <span class="hljs-comment">// 获取最优配置</span><br>    <span class="hljs-built_in">cudaOccupancyMaxPotentialBlockSize</span>(<br>        &amp;minGridSize, &amp;blockSize, MyKernel, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<br>    <br>    <span class="hljs-comment">// 根据数据量调整网格大小</span><br>    gridSize = (count + blockSize - <span class="hljs-number">1</span>) / blockSize;<br>    MyKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(array, count);<br>    <br>    <span class="hljs-built_in">cudaDeviceSynchronize</span>();<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<h3 id="最大化内存吞吐量">最大化内存吞吐量</h3>
<p>一、内存传输优化原则</p>
<ol>
<li>最小化主机-设备数据传输</li>
</ol>
<ul>
<li>
<p><strong>数据传输层级对比</strong>：</p>
<table>
<thead>
<tr>
<th style="text-align:left">传输类型</th>
<th style="text-align:left">带宽</th>
<th style="text-align:left">延迟</th>
<th style="text-align:left">优化建议</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">主机↔设备</td>
<td style="text-align:left">低</td>
<td style="text-align:left">高</td>
<td style="text-align:left">尽量减少</td>
</tr>
<tr>
<td style="text-align:left">全局内存访问</td>
<td style="text-align:left">中</td>
<td style="text-align:left">中</td>
<td style="text-align:left">优化访问模式</td>
</tr>
<tr>
<td style="text-align:left">片上内存(共享/L1)</td>
<td style="text-align:left">高</td>
<td style="text-align:left">低</td>
<td style="text-align:left">最大化使用</td>
</tr>
</tbody>
</table>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 坏实践：频繁小数据传输</span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;<span class="hljs-number">1000</span>; i++) &#123;<br>    <span class="hljs-built_in">cudaMemcpy</span>(devPtr+i, hostPtr+i, <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br>&#125;<br><br><span class="hljs-comment">// 好实践：批量传输</span><br><span class="hljs-built_in">cudaMemcpy</span>(devPtr, hostPtr, <span class="hljs-number">1000</span>*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), cudaMemcpyHostToDevice);<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>使用固定内存(pinned memory)</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span>* hostPtr;<br><span class="hljs-built_in">cudaHostAlloc</span>(&amp;hostPtr, size, cudaHostAllocDefault);  <span class="hljs-comment">// 分配固定内存</span><br>kernel&lt;&lt;&lt;...&gt;&gt;&gt;(devPtr, ...);<br><span class="hljs-built_in">cudaMemcpyAsync</span>(hostPtr, devPtr, size, cudaMemcpyDeviceToHost, stream);<br></code></pre></td></tr></table></figure>
<p>二、全局内存访问优化</p>
<ol>
<li>合并访问模式</li>
</ol>
<ul>
<li><strong>理想情况</strong>：一个warp的32个线程访问连续的128字节内存块</li>
<li><strong>访问模式对比</strong>：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 非合并访问(低效)</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">badAccess</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input, <span class="hljs-type">int</span> stride)</span> </span>&#123;<br>    <span class="hljs-type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;<br>    output[tid] = input[tid * stride];  <span class="hljs-comment">// 跨步访问</span><br>&#125;<br><br><span class="hljs-comment">// 合并访问(高效)</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">goodAccess</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input)</span> </span>&#123;<br>    <span class="hljs-type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;<br>    output[tid] = input[tid];  <span class="hljs-comment">// 连续访问</span><br>&#125;<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>二维数组的特殊处理</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 使用cudaMallocPitch处理非对齐宽度</span><br><span class="hljs-type">size_t</span> pitch;<br><span class="hljs-type">float</span>* devPtr;<br><span class="hljs-built_in">cudaMallocPitch</span>(&amp;devPtr, &amp;pitch, width*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height);<br><br><span class="hljs-comment">// 拷贝时指定pitch</span><br><span class="hljs-built_in">cudaMemcpy2D</span>(devPtr, pitch, hostPtr, width*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), <br>             width*<span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>), height, cudaMemcpyHostToDevice);<br></code></pre></td></tr></table></figure>
<p>三、各类内存特性与优化</p>
<ol>
<li>
<p>共享内存使用技巧</p>
<p><strong>bank冲突避免</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__shared__ <span class="hljs-type">float</span> tile[<span class="hljs-number">32</span>][<span class="hljs-number">32</span><span class="hljs-number">+1</span>]; <span class="hljs-comment">// 添加padding消除bank冲突</span><br><br><span class="hljs-comment">// 无冲突访问模式</span><br><span class="hljs-type">float</span> val = tile[threadIdx.y][threadIdx.x]; <span class="hljs-comment">// 线程ID与bank分布匹配</span><br></code></pre></td></tr></table></figure>
<p><strong>典型使用模式</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">sharedMemExample</span><span class="hljs-params">(<span class="hljs-type">float</span>* output, <span class="hljs-type">float</span>* input)</span> </span>&#123;<br>    __shared__ <span class="hljs-type">float</span> temp[BLOCK_SIZE];<br>    <span class="hljs-type">int</span> tid = threadIdx.x;<br>    <br>    <span class="hljs-comment">// 1. 从全局内存加载到共享内存</span><br>    temp[tid] = input[blockIdx.x * blockDim.x + tid];<br>    <br>    <span class="hljs-comment">// 2. 同步等待所有线程完成加载</span><br>    __syncthreads();<br>    <br>    <span class="hljs-comment">// 3. 处理共享内存数据</span><br>    temp[tid] *= <span class="hljs-number">2.0f</span>;<br>    <br>    <span class="hljs-comment">// 4. 同步确保处理完成</span><br>    __syncthreads();<br>    <br>    <span class="hljs-comment">// 5. 写回全局内存</span><br>    output[blockIdx.x * blockDim.x + tid] = temp[tid];<br>&#125;<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>常量内存与纹理内存</p>
<p><strong>常量内存适用场景</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp">__constant__ <span class="hljs-type">float</span> constData[<span class="hljs-number">256</span>];<br><br><span class="hljs-comment">// 初始化常量内存</span><br><span class="hljs-built_in">cudaMemcpyToSymbol</span>(constData, hostData, <span class="hljs-built_in">sizeof</span>(hostData));<br></code></pre></td></tr></table></figure>
<p><strong>纹理内存优势</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp">texture&lt;<span class="hljs-type">float</span>, <span class="hljs-number">2</span>, cudaReadModeElementType&gt; texRef;<br><br><span class="hljs-comment">// 绑定纹理</span><br><span class="hljs-built_in">cudaBindTexture2D</span>(<span class="hljs-number">0</span>, texRef, devPtr, channelDesc, width, height, pitch);<br><br><span class="hljs-comment">// 内核中访问</span><br><span class="hljs-type">float</span> val = <span class="hljs-built_in">tex2D</span>(texRef, x, y);<br></code></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="最大化指令吞吐量">最大化指令吞吐量</h3>
<p>一、算术运算优化策略</p>
<ol>
<li>
<p>精度与速度的权衡</p>
<table>
<thead>
<tr>
<th style="text-align:left">运算类型</th>
<th style="text-align:left">推荐操作</th>
<th style="text-align:left">加速比</th>
<th style="text-align:left">适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">单精度除法</td>
<td style="text-align:left">使用<code>__fdividef(x,y)</code></td>
<td style="text-align:left">2-5倍</td>
<td style="text-align:left">精度要求不高时</td>
</tr>
<tr>
<td style="text-align:left">平方根倒数</td>
<td style="text-align:left">直接调用<code>rsqrtf()</code></td>
<td style="text-align:left">3倍</td>
<td style="text-align:left">图形渲染、物理模拟</td>
</tr>
<tr>
<td style="text-align:left">三角函数</td>
<td style="text-align:left">控制参数范围&lt;105615.0f</td>
<td style="text-align:left">10倍</td>
<td style="text-align:left">避免慢速路径</td>
</tr>
</tbody>
</table>
</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 快速除法示例</span><br><span class="hljs-type">float</span> result = __fdividef(a, b);  <span class="hljs-comment">// 比常规除法快</span><br><br><span class="hljs-comment">// 优化三角函数调用</span><br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">fabs</span>(x) &lt; <span class="hljs-number">105615.0f</span>) &#123;        <span class="hljs-comment">// 保持使用快速路径</span><br>    <span class="hljs-type">float</span> s = <span class="hljs-built_in">sinf</span>(x); <br>&#125;<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>半精度浮点运算技巧</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 使用half2类型实现双倍吞吐量</span><br><span class="hljs-function">__global__ <span class="hljs-type">void</span> <span class="hljs-title">halfPrecisionKernel</span><span class="hljs-params">(half2* data)</span> </span>&#123;<br>    half2 a = data[threadIdx.x];<br>    half2 b = __hadd2(a, <span class="hljs-built_in">make_half2</span>(<span class="hljs-number">1.0f</span>, <span class="hljs-number">1.0f</span>)); <span class="hljs-comment">// 同时加两个数</span><br>    data[threadIdx.x] = __hmul2(a, b);            <span class="hljs-comment">// 同时乘两个数</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>二、控制流优化方法</p>
<ol>
<li>避免分支分歧（<strong>Warp对齐条件</strong>：确保同一warp内线程执行相同路径）</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 差实践：基于threadIdx的条件分支</span><br><span class="hljs-keyword">if</span>(threadIdx.x % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">/* 导致warp分歧 */</span> &#125;<br><br><span class="hljs-comment">// 好实践：Warp对齐条件</span><br><span class="hljs-keyword">if</span>((threadIdx.x / warpSize) % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) &#123; <span class="hljs-comment">/* 保持warp统一 */</span> &#125;、<br></code></pre></td></tr></table></figure>
<ol start="2">
<li>循环展开优化</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> unroll 4  <span class="hljs-comment">// 手动指定展开因子</span></span><br><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;N; i++) &#123;<br>    <span class="hljs-comment">// 循环体</span><br>&#125;<br></code></pre></td></tr></table></figure>
<p>三. 同步指令性能</p>
<h3 id="各架构同步吞吐量对比">各架构同步吞吐量对比</h3>
<table>
<thead>
<tr>
<th style="text-align:left">计算能力</th>
<th style="text-align:left"><code>__syncthreads()</code>吞吐量</th>
<th style="text-align:left">相当于每周期操作数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">3.x</td>
<td style="text-align:left">高</td>
<td style="text-align:left">128 ops/cycle</td>
</tr>
<tr>
<td style="text-align:left">5.x/6.1/6.2</td>
<td style="text-align:left">中</td>
<td style="text-align:left">64 ops/cycle</td>
</tr>
<tr>
<td style="text-align:left">6.0</td>
<td style="text-align:left">低</td>
<td style="text-align:left">32 ops/cycle</td>
</tr>
<tr>
<td style="text-align:left">7.x</td>
<td style="text-align:left">最低</td>
<td style="text-align:left">16 ops/cycle</td>
</tr>
</tbody>
</table>
<p>四. 类型转换优化</p>
<ol>
<li>避免隐式转换开销</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// 差实践：引发int转换</span><br><span class="hljs-type">short</span> a = b + c;  <span class="hljs-comment">// 转换为int运算</span><br><br><span class="hljs-comment">// 好实践：使用合适类型</span><br><span class="hljs-type">int</span> a = b + c;    <span class="hljs-comment">// 无转换开销</span><br></code></pre></td></tr></table></figure>
<ol start="2">
<li>浮点常量优化</li>
</ol>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">float</span> a = <span class="hljs-number">3.141592653589793</span>;   <span class="hljs-comment">// 引发双精度到单精度转换</span><br><span class="hljs-type">float</span> b = <span class="hljs-number">3.141592653589793f</span>;  <span class="hljs-comment">// 直接使用单精度常量</span><br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="../../../../categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/" class="category-chain-item">高性能计算</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CUDA基础</div>
      <div>https://github.com/Diffcc/Diffcc.github.io/2025/06/11/20250611/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Diffcc</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年6月11日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="../../../07/12/20250712/" title="大模型量化技术">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">大模型量化技术</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="../../10/20250610/" title="Perf Linux使用教程">
                        <span class="hidden-mobile">Perf Linux使用教程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"KJGUBUZKqbURalPPi4RThE5j-gzGzoHsz","appKey":"LLhQIl1R0Kiu8YUUshoGpnuy","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访问 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="../../../../js/events.js" ></script>
<script  src="../../../../js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="../../../../js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="../../../../js/leancloud.js" ></script>

  <script  src="../../../../js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="../../../../js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
