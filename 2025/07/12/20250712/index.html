

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="../../../../img/ling.jpg">
  <link rel="icon" href="../../../../img/ling.jpg">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Diffcc">
  <meta name="keywords" content="">
  
    <meta name="description" content="现有的基于Transformer架构的大模型，参数量规模极大，往往一个普通的模型动不动就几个G占用，对于边缘端设备来说，内存和计算能力都相对较低的情况下，压缩模型，同时尽量保证较高的推理性能尤为重要。 DeepSeek模型详解：https:&#x2F;&#x2F;cloud.tencent.com&#x2F;developer&#x2F;article&#x2F;2497217 Qwen3模型优化：https:&#x2F;&#x2F;www.zhihu.com&#x2F;qu">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型量化技术">
<meta property="og:url" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/index.html">
<meta property="og:site_name">
<meta property="og:description" content="现有的基于Transformer架构的大模型，参数量规模极大，往往一个普通的模型动不动就几个G占用，对于边缘端设备来说，内存和计算能力都相对较低的情况下，压缩模型，同时尽量保证较高的推理性能尤为重要。 DeepSeek模型详解：https:&#x2F;&#x2F;cloud.tencent.com&#x2F;developer&#x2F;article&#x2F;2497217 Qwen3模型优化：https:&#x2F;&#x2F;www.zhihu.com&#x2F;qu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96.png">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/%E4%B8%8D%E5%90%8C%E9%87%8F%E5%8C%96%E6%96%B9%E5%BC%8F.jpg">
<meta property="og:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/%E9%87%8F%E5%8C%96%E7%B2%92%E5%BA%A6.png">
<meta property="article:published_time" content="2025-07-12T05:05:00.000Z">
<meta property="article:modified_time" content="2025-07-12T07:04:38.039Z">
<meta property="article:author" content="Diffcc">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F.png">
  
  
  
  <title>大模型量化技术 - </title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="../../../../css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="../../../../css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="../../../../css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"github.com","root":"/Diffcc/Diffcc.github.io/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"KJGUBUZKqbURalPPi4RThE5j-gzGzoHsz","app_key":"LLhQIl1R0Kiu8YUUshoGpnuy","server_url":"https://kjgubuzk.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/Diffcc/Diffcc.github.io/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="../../../../js/utils.js" ></script>
  <script  src="../../../../js/color-schema.js" ></script>
  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="../../../../index.html">
      <strong>C.</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../index.html" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="../../../../about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('../../../../img/default.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="大模型量化技术"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-07-12 13:05" pubdate>
          2025年7月12日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          29 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">大模型量化技术</h1>
            
            
              <div class="markdown-body">
                
                <p>现有的基于Transformer架构的大模型，参数量规模极大，往往一个普通的模型动不动就几个G占用，对于边缘端设备来说，内存和计算能力都相对较低的情况下，压缩模型，同时尽量保证较高的推理性能尤为重要。</p>
<p>DeepSeek模型详解：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2497217">https://cloud.tencent.com/developer/article/2497217</a></p>
<p>Qwen3模型优化：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/1914286810902827620/answer/1914361315604031301">https://www.zhihu.com/question/1914286810902827620/answer/1914361315604031301</a></p>
<span id="more"></span>
<p>本文主要涉及模型压缩中的量化技术（Quantization），对于其他压缩技术，例如剪枝（Pruning）、知识蒸馏（Knowledge Distillation）、低秩分解（Low-Rank Factorization）等，读者可自行了解。</p>
<h3 id="量化原理">量化原理</h3>
<p>常见的数据类型有如下几种（Float32，TF32，FP16，BF16）等，其中后缀数字表明1个符号位 + 指数位 + 尾数位，通俗的理解，指数位代表该数的量级，也就是范围，而尾数位则代表了该数的有效尾数，所以我们在比较Float类型的数字是否相等时，往往取二者的差值小于某个小数阈值，而不同的尾数个数，对于阈值的要求也不一样。</p>
<p>而模型量化则是将模型的参数从高精度的数据类型（例如Float32）转换为低精度的数据类型（如INT8，FP8），进而减少模型的参数量大小。</p>
<p><img src="%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="数据格式"></p>
<h4 id="量化对象">量化对象</h4>
<p>模型量化的对象包括以下几个方面：</p>
<ul>
<li>权重（weight）：weight的量化最为常见，权重的减小可以减少模型的内存占用，权重由于在训练完成之后固定，其数值范围和数值无关，可以离线完成量化，通常比较简单。</li>
<li>激活（Activation）：activation在整个模型中占据了内存的大头，所以量化激活可以更近一步减少内存占用，同时结合权重量化可以充分利用整数计算获得模型推理性能的提升，但是由于激活输出会随着输入的改变而改变，所以需要统计数据的动态范围，更难量化。</li>
<li>KV Cache：KV Cache在大模型中会消耗许多内存，因此，量化KV Cache对提高模型长序列生成的吞吐量至关重要。</li>
<li>梯度（Gradients）：梯度量化主要用于训练场景，量化梯度可以减少浮点数梯度在分布式计算中的通信开销，同时减少反向传播的开销。</li>
</ul>
<h4 id="量化形式">量化形式</h4>
<p>根据量化数表示的原始数据是否均匀，可以将量化方法划分为对称量化和非对称量化，实际网络中的权重和激活往往是不均匀的，理应采用非对称量化减少精度损失，但是由于非对称量化的计算复杂度较高，通常采用线性量化：</p>
<p>$q = clip(round(r/s) + z, q_{min},q_{max})$</p>
<p>原始浮点数$r$ 除以量化间隔$s$, 得到缩放后的值$r/s$, 这一步将$r$映射到一个更小的范围，便于后续的整数表示，加上偏置$z$, 调整数据零点的位置，如果$z = 0$, 表示堆成量化，数据的零点居中；反之，则为非对称量化，对称量化可以避免量化算子在推理中计算$z$相关的部分，降低推理时的时间复杂度；非对称量化可以根据实际数据的分布确定最大值和最大值，更加充分利用量化数据信息，使得量化导致的损失更低。$round(·)$表示取整操作，得到最接近的整数值，$clip(·)$表示截断操作，将取整之后的结果限制在$[q_{min}, q_{max}]$范围内，防止超出量化之后的数值表示范围。</p>
<p><img src="%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E9%87%8F%E5%8C%96.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="对称量化和非对称量化"></p>
<h4 id="量化粒度">量化粒度</h4>
<p>根据量化参数$s$和$z$的共享范围（即量化粒度），量化方法可以按照如下粒度划分：</p>
<ul>
<li>per-tensor(per-layer)量化：每层或每个张量只有一个缩放因子，张量内的所有值都被这个缩放因子量化。</li>
<li>per-channel量化：卷积核中的每个通道都有不同的缩放因子。</li>
<li>per-token量化：针对激活而言，针对每一行进行量化。在LLM中，通常和per-channel量化配合使用，如：逐token量化激活，逐channel量化权重。</li>
<li>per-group/group-wise: 分组量化，以组为单位，分组量化的特殊情况是，将每个密集的矩阵都视为一个组，每个矩阵都有自己的量化范围。而更为普遍的情况是将每个密集矩阵按照输出神经元进行分割，每个连续的N输出神经元为一个组。比如：GPTQ、AWQ中使用128个元素为一组进行量化。有些地方也称为子通道分组（Sub-channel-wise）量化，即将通道划分为更小的子组，以实现更细粒度的精度控制。它的粒度处于 per-tensor 和 per-channel 之间。比如：group_size=128对应一个量化系数，共有 ⌊T/group_size⌋ * ⌊C0/group_size⌋ 个。当 group_size=1 时，逐组量化与逐层量化等价；当 group_size=num_filters（如：dw（Depthwise）将卷积核变成单通道）时，逐组量化与逐通道量化等价。</li>
</ul>
<p><img src="%E4%B8%8D%E5%90%8C%E9%87%8F%E5%8C%96%E6%96%B9%E5%BC%8F.jpg" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="不同量化方式"></p>
<p>下图中$X$表示激活Tensor，$W$表示权重Tensor。</p>
<p><img src="%E9%87%8F%E5%8C%96%E7%B2%92%E5%BA%A6.png" srcset="/Diffcc/Diffcc.github.io/img/loading.gif" lazyload alt="量化粒度"></p>
<h4 id="静态量化和动态量化">静态量化和动态量化</h4>
<p><strong>对于激活而言， 量化有动态量化和静态量化之分。</strong></p>
<p>通常，<strong>对于激活而言</strong>，静态量化是指如果采用具有代表性的校准数据集来为其生成缩放因子和零点，这些参数在模型的整个生命周期中保持不变。静态量化的优点在于推理时的计算效率较高，因为它不需要在运行时动态计算量化参数。然而，由于量化参数是固定的，静态量化可能会引入一些量化误差，从而影响模型的精度</p>
<p>而动态量化是指在每次前向传递期间计算激活的最小值和最大值，以提供动态的缩放因子以实现高精度。动态量化的优点在于它可以更准确地表示模型的激活值，因为它考虑了运行时的实际数据分布。然而，这种方法的缺点是可能会增加计算开销，因为需要在运行时计算量化参数。动态量化适合于那些对模型精度要求较高的应用场景，尤其是当模型的输入数据分布变化较大时。</p>
<p>目前，常见的是对激活<strong>使用静态量化</strong>，其中最小/最大范围是在离线校准阶段计算的。但由于LLM中激活范围差异巨大，将<strong>导致准确度显著下降</strong>。</p>
<h4 id="离线量化和在线量化">离线量化和在线量化</h4>
<p>离线量化是指模型上线前进行量化并生成缩放因子，而在线量化是指模型运行时进行量化。</p>
<p>动态与静态量化的区别在于是否使用校准集，而离线与在线量化的区别则是量化的时机不同。简单理解就是说<strong>离线静态量化</strong>是指在模型上线推理前使用校准集生成缩放因子，对权重和激活进行量化。<strong>在线动态量化</strong>是指在模型上线推理时，在每次前向传播过程中实时生成缩放因子，对模型对权重和激活进行量化。 而<strong>离线动态量化</strong>通常是指<strong>对权重在运行前先进行量化，对激活在运行时进行动态量化。</strong></p>
<h4 id="量化阶段">量化阶段</h4>
<p>根据应用量化压缩模型的阶段，可以将模型量化分为：</p>
<ul>
<li>量化感知训练（Quantization Aware Training, QAT）：在模型训练过程中加入伪量化算子，通过训练时统计输入输出的数据范围可以提升量化后模型的精度，适用于对模型精度要求较高的场景；其量化目标无缝地集成到模型的训练过程中。这种方法使LLM在训练过程中适应低精度表示，增强其处理由量化引起的精度损失的能力。这种适应旨在量化过程之后保持更高性能。</li>
<li>量化感知微调（Quantization-Aware Fine-tuning，<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=251400333&amp;content_type=Article&amp;match_order=1&amp;q=QAF&amp;zhida_source=entity">QAF</a>）：在微调过程中对LLM进行量化。主要目标是确保经过微调的LLM在量化为较低位宽后仍保持性能。通过将量化感知整合到微调中，以在模型压缩和保持性能之间取得平衡。</li>
<li>训练后量化（Post Training Quantization, PTQ）：在LLM训练完成后对其参数进行量化，只需要少量校准数据，适用于追求高易用性和缺乏训练资源的场景。主要目标是减少LLM的存储和计算复杂性，而无需对LLM架构进行修改或进行重新训练。PTQ的主要优势在于其简单性和高效性。但PTQ可能会在量化过程中引入一定程度的精度损失。</li>
</ul>
<h5 id="量化感知训练">量化感知训练</h5>
<p>量化感知训练是在训练过程中模拟量化，<strong>利用伪量化算子将量化带来的精度损失计入训练误差，使得优化器能在训练过程中尽量减少量化误差</strong>，得到更高的模型精度。量化感知训练的具体流程如下：</p>
<ul>
<li><strong>初始化</strong>：设置权重和激活值的范围$q_{min}$和$q_{max}$的初始值；</li>
<li><strong>构建模拟量化网络</strong>：在需要量化的权重和激活值后插入伪量化算子；</li>
<li><strong>量化训练</strong>：重复执行以下步骤直到网络收敛，<strong>计算量化网络层的权重和激活值的范围</strong>$q_{min}$和$q_{max}$，并<strong>根据该范围将量化损失带入到前向推理和后向参数更新的过程中</strong>；</li>
<li><strong>导出量化网络</strong>：获取$q_{min}$和$q_{max}$，并计算量化参数$s$和$z$；<strong>将量化参数代入量化公式中，转换网络中的权重为量化整数值；删除伪量化算子，在量化网络层前后分别插入量化和反量化算子</strong>。</li>
</ul>
<p>伪量化算子的数学形式与实际量化公式类似，但增加了梯度传播机制。例如，对权重或激活值 x<em>x</em> 的伪量化过程如下:</p>
<p>$x_{fake_quant} = clip(round{x/s + z} - z) * s$</p>
<p>在前向传播时，$round()$和$clip()$模拟量化， 对输入值进行缩放、取整、截断，再反缩放回原始范围。</p>
<p>在反向传播时，梯度直接传递（STE），忽略$round()$和$clip()$的不可微性：</p>
<p>$dL/dx = dL/d{x_{fake_quant}}$</p>
<h5 id="训练后量化">训练后量化</h5>
<p>训练后量化也可以分成两种，权重量化和全量化。</p>
<ul>
<li>权重量化<strong>仅量化模型的权重</strong>以压缩模型的大小，在推理时将权重反量化为原始的float32数据，后续推理流程与普通的float32模型一致。权重量化的好处是不需要校准数据集，不需要实现量化算子，且模型的精度误差较小，由于实际推理使用的仍然是float32算子，所以推理性能不会提高。</li>
<li>全量化<strong>不仅会量化模型的权重，还会量化模型的激活值</strong>，在模型推理时执行量化算子来加快模型的推理速度。为了量化激活值，需要用户提供一定数量的校准数据集用于统计每一层激活值的分布，并对量化后的算子做校准。<strong>校准数据集可以来自训练数据集或者真实场景的输入数据，需要数量通常非常小</strong>。</li>
</ul>
<p>在量化激活值时会<strong>以校准数据集为输入，执行推理流程然后统计每层激活值的数据分布并得到相应的量化参数</strong>。具体的操作流程如下：</p>
<ul>
<li>使用直方图统计的方式<strong>得到原始float32数据的统计分布</strong> $P_f$；</li>
<li>在给定的搜索空间中选取若干个$q_{min}$和$q_{max}$分别<strong>对激活值量化</strong>，得到量化后的数据$Q_q$；</li>
<li>使用直方图统计得到$Q_q$的<strong>统计分布</strong>;</li>
<li>计算每个$Q_a$与$P_f$的统计分布差异，并<strong>找到差异性最低的一个</strong>对应的 $q_{min}$和$q_{max}$来计算相应的量化参数，常见的用于度量分布差异的指标包括KL散度(Kullback-Leibler Divergence)、对称KL散度(Symmetric Kullback-Leibler Divergence)和JS散度(Jenson-Shannon Divergence)</li>
</ul>
<p>除此之外，由于量化存在固有误差，还需要<strong>校正量化误差</strong>。以矩阵乘为例$a =  \sum_{i=1}^{N} w_ix_i + b$，$w$表示权重，$x$表示激活值，$b$表示偏置。</p>
<p>首先需要对量化的均值做校正，对float32算子和量化算子输出的每个通道求平均，假设某个通道i的float32算子输出均值为$a_i$，量化算子反量化输出均值为$a_{qi}$，将这个通道两个均值的差$a_i - a_{qi}$加到对应的通道上即可使得最终的输出均值和float32一致。</p>
<p>另外，还需要<strong>保证量化后的分布和量化前是一致的</strong>，设某个通道权重数据的均值、方差为$E(w_c)$、$||w_c - E(w_c)||$，量化后的均值和方差为$E(\hat{w_c})$、$||\hat{w_c} - E(\hat{w_c})||$，对权重如下校正：</p>
<p>$\hat{w}_c \leftarrow \zeta_c (\hat{w}_c + u_c) $</p>
<p>其中：</p>
<p>$u_c = E(w_c) - E(\hat{w}_c) $</p>
<p>$\zeta_c = \frac{|w_c - E(w_c)|}{|\hat{w}_c - E(\hat{w}_c)|} $</p>
<h3 id="量化方法">量化方法</h3>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="../../../../categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/" class="category-chain-item">高性能计算</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>大模型量化技术</div>
      <div>https://github.com/Diffcc/Diffcc.github.io/2025/07/12/20250712/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Diffcc</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年7月12日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="../../../06/11/20250611/" title="CUDA基础">
                        <span class="hidden-mobile">CUDA基础</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"KJGUBUZKqbURalPPi4RThE5j-gzGzoHsz","appKey":"LLhQIl1R0Kiu8YUUshoGpnuy","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访问 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="../../../../js/events.js" ></script>
<script  src="../../../../js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="../../../../js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="../../../../js/leancloud.js" ></script>

  <script  src="../../../../js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="../../../../js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
